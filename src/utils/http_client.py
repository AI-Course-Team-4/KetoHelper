"""
ğŸŒ HTTP í´ë¼ì´ì–¸íŠ¸ ëª¨ë“ˆ
- Playwright ê¸°ë°˜ í¬ë¡¤ë§
- ìë™ ì¬ì‹œë„ ë° ë°±ì˜¤í”„
- ì°¨ë‹¨ ê°ì§€ ë° íšŒí”¼
- ì†ë„ ì œí•œ ì¤€ìˆ˜
"""

import asyncio
import time
import random
from typing import Optional, Dict, Any, List
from urllib.parse import urljoin, urlparse
from pathlib import Path

from playwright.async_api import async_playwright, Page, Browser, BrowserContext
from playwright.async_api import TimeoutError as PlaywrightTimeoutError

from .config_loader import get_config
from .logger import get_logger, log_request, log_blocking_detected, log_rate_limit


class RateLimiter:
    """ì‚¬ì´íŠ¸ë³„ ì†ë„ ì œí•œ ê´€ë¦¬"""
    
    def __init__(self):
        self.site_last_request = {}  # ì‚¬ì´íŠ¸ë³„ ë§ˆì§€ë§‰ ìš”ì²­ ì‹œê°„
        self.site_qps = {}          # ì‚¬ì´íŠ¸ë³„ í˜„ì¬ QPS
        
    async def wait_for_rate_limit(self, site: str, target_qps: float):
        """ì†ë„ ì œí•œì— ë”°ë¥¸ ëŒ€ê¸°"""
        now = time.time()
        last_request = self.site_last_request.get(site, 0)
        
        # QPSì— ë”°ë¥¸ ìµœì†Œ ëŒ€ê¸° ì‹œê°„ ê³„ì‚°
        min_interval = 1.0 / target_qps
        elapsed = now - last_request
        
        if elapsed < min_interval:
            wait_time = min_interval - elapsed
            await asyncio.sleep(wait_time)
        
        self.site_last_request[site] = time.time()
    
    def update_qps(self, site: str, new_qps: float):
        """ì‚¬ì´íŠ¸ë³„ QPS ì—…ë°ì´íŠ¸"""
        old_qps = self.site_qps.get(site, 0)
        self.site_qps[site] = new_qps
        
        if old_qps != new_qps:
            log_rate_limit(site, old_qps, new_qps)


class BlockingDetector:
    """ì°¨ë‹¨ ê°ì§€ê¸°"""
    
    def __init__(self, config):
        self.config = config
        self.blocking_indicators = config.raw_config.get("error_handling", {}).get(
            "blocking_indicators", []
        )
    
    def detect_blocking(self, content: str, url: str) -> Optional[str]:
        """ì°¨ë‹¨ ê°ì§€"""
        content_lower = content.lower()
        
        for indicator in self.blocking_indicators:
            if indicator.lower() in content_lower:
                return indicator
                
        return None
    
    def is_empty_page(self, content: str, parser_config: Dict[str, Any]) -> bool:
        """ë¹ˆ í˜ì´ì§€ ê°ì§€"""
        # HTML ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìŒ
        if len(content.strip()) < 100:
            return True
            
        # íŒŒì„œ ì„¤ì •ì— ì •ì˜ëœ ë¹ˆ í˜ì´ì§€ íŒ¨í„´ í™•ì¸
        empty_patterns = parser_config.get("blocking_detection", {}).get(
            "empty_page_selectors", []
        )
        
        for pattern in empty_patterns:
            if pattern in content:
                return True
                
        return False


class HttpClient:
    """ê³ ê¸‰ HTTP í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, config_path: Optional[str] = None):
        self.config = get_config(config_path)
        self.logger = get_logger("http_client")
        self.rate_limiter = RateLimiter()
        self.blocking_detector = BlockingDetector(self.config)
        
        # Playwright ì¸ìŠ¤í„´ìŠ¤
        self.playwright = None
        self.browser = None
        self.contexts = {}  # ì‚¬ì´íŠ¸ë³„ ë¸Œë¼ìš°ì € ì»¨í…ìŠ¤íŠ¸
        
        # í†µê³„
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "blocked_requests": 0
        }
    
    async def __aenter__(self):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        await self.start()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        await self.close()
    
    async def start(self):
        """í´ë¼ì´ì–¸íŠ¸ ì‹œì‘"""
        if self.playwright is None:
            self.playwright = await async_playwright().start()
            
            # ë¸Œë¼ìš°ì € ì‹œì‘
            playwright_config = self.config.crawler.playwright
            self.browser = await self.playwright.chromium.launch(
                headless=playwright_config["headless"],
                slow_mo=playwright_config["slow_mo"]
            )
            
            self.logger.info("HTTP í´ë¼ì´ì–¸íŠ¸ ì‹œì‘ë¨")
    
    async def close(self):
        """í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ"""
        # ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ ì¢…ë£Œ
        for context in self.contexts.values():
            await context.close()
        self.contexts.clear()
        
        # ë¸Œë¼ìš°ì € ì¢…ë£Œ
        if self.browser:
            await self.browser.close()
            self.browser = None
            
        # Playwright ì¢…ë£Œ
        if self.playwright:
            await self.playwright.stop()
            self.playwright = None
            
        self.logger.info("HTTP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œë¨")
    
    async def get_context(self, site: str) -> BrowserContext:
        """ì‚¬ì´íŠ¸ë³„ ë¸Œë¼ìš°ì € ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜"""
        if site not in self.contexts:
            # ìƒˆ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            viewport = self.config.crawler.playwright["viewport"]
            user_agent = self.config.get_user_agent()
            
            self.contexts[site] = await self.browser.new_context(
                viewport=viewport,
                user_agent=user_agent,
                # ë¦¬ì†ŒìŠ¤ ì°¨ë‹¨ìœ¼ë¡œ ì†ë„ í–¥ìƒ
                # (ì´ë¯¸ì§€, í°íŠ¸, ë¯¸ë””ì–´ ì°¨ë‹¨)
            )
            
            # ë¦¬ì†ŒìŠ¤ ì°¨ë‹¨ ì„¤ì •
            await self.contexts[site].route(
                "**/*", 
                lambda route: self._handle_route(route)
            )
            
        return self.contexts[site]
    
    async def _handle_route(self, route):
        """ë¦¬ì†ŒìŠ¤ ë¼ìš°íŒ… ì²˜ë¦¬ (ì°¨ë‹¨)"""
        resource_type = route.request.resource_type
        
        # ë¶ˆí•„ìš”í•œ ë¦¬ì†ŒìŠ¤ ì°¨ë‹¨
        if resource_type in ["image", "font", "media", "websocket"]:
            await route.abort()
        else:
            await route.continue_()
    
    async def fetch(self, url: str, site: str, 
                   parser_config: Optional[Dict[str, Any]] = None,
                   max_retries: Optional[int] = None,
                   custom_headers: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
        """ì›¹í˜ì´ì§€ í¬ë¡¤ë§"""
        if not await self._is_started():
            await self.start()
            
        max_retries = max_retries or self.config.crawler.retry["max_attempts"]
        start_time = time.time()
        last_error = None
        
        for attempt in range(max_retries):
            try:
                # ì†ë„ ì œí•œ ì ìš©
                target_qps = self.config.get_rate_limit(site)
                await self.rate_limiter.wait_for_rate_limit(site, target_qps)
                
                # ìš”ì²­ ì‹¤í–‰
                result = await self._fetch_page(
                    url, site, parser_config, custom_headers
                )
                
                # ì„±ê³µ í†µê³„ ì—…ë°ì´íŠ¸
                self.stats["total_requests"] += 1
                self.stats["successful_requests"] += 1
                
                # ì‘ë‹µ ì‹œê°„ ë¡œê¹…
                response_time = time.time() - start_time
                log_request("GET", url, 200, response_time, site)
                
                return result
                
            except Exception as e:
                last_error = e
                self.stats["total_requests"] += 1
                self.stats["failed_requests"] += 1
                
                self.logger.warning(
                    f"ìš”ì²­ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {url} - {e}"
                )
                
                # ì¬ì‹œë„ ì „ ë°±ì˜¤í”„
                if attempt < max_retries - 1:
                    backoff_time = await self._calculate_backoff(attempt, site, str(e))
                    await asyncio.sleep(backoff_time)
        
        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
        response_time = time.time() - start_time
        log_request("GET", url, 500, response_time, site)
        
        raise Exception(f"ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨: {url} - {last_error}")
    
    async def _fetch_page(self, url: str, site: str, 
                         parser_config: Optional[Dict[str, Any]],
                         custom_headers: Optional[Dict[str, str]]) -> Dict[str, Any]:
        """ì‹¤ì œ í˜ì´ì§€ í¬ë¡¤ë§"""
        context = await self.get_context(site)
        page = await context.new_page()
        
        try:
            # ì»¤ìŠ¤í…€ í—¤ë” ì„¤ì •
            if custom_headers:
                await page.set_extra_http_headers(custom_headers)
            
            # í˜ì´ì§€ ë¡œë“œ
            timeout = self.config.crawler.page_timeout * 1000
            
            await page.goto(url, timeout=timeout, wait_until="networkidle")
            
            # í˜ì´ì§€ ë¡œë”© ì™„ë£Œ ëŒ€ê¸° (íŒŒì„œ ì„¤ì •ì— ë”°ë¼)
            if parser_config:
                await self._wait_for_page_load(page, parser_config)
            
            # HTML ì½˜í…ì¸  ì¶”ì¶œ
            content = await page.content()
            
            # ì°¨ë‹¨ ê°ì§€
            blocking_indicator = self.blocking_detector.detect_blocking(content, url)
            if blocking_indicator:
                self.stats["blocked_requests"] += 1
                log_blocking_detected(site, url, blocking_indicator)
                raise Exception(f"ì°¨ë‹¨ ê°ì§€: {blocking_indicator}")
            
            # ë¹ˆ í˜ì´ì§€ ê°ì§€
            if parser_config and self.blocking_detector.is_empty_page(content, parser_config):
                raise Exception("ë¹ˆ í˜ì´ì§€ ê°ì§€")
            
            # í˜ì´ì§€ ì •ë³´ ë°˜í™˜
            return {
                "url": url,
                "content": content,
                "title": await page.title(),
                "status": "success",
                "site": site
            }
            
        except PlaywrightTimeoutError:
            raise Exception("í˜ì´ì§€ ë¡œë“œ íƒ€ì„ì•„ì›ƒ")
        except Exception as e:
            raise e
        finally:
            await page.close()
    
    async def _wait_for_page_load(self, page: Page, parser_config: Dict[str, Any]):
        """í˜ì´ì§€ ë¡œë”© ì™„ë£Œ ëŒ€ê¸°"""
        timing_config = parser_config.get("timing", {})
        loading_selectors = parser_config.get("blocking_detection", {}).get(
            "loading_complete_selectors", []
        )
        
        # íŠ¹ì • ìš”ì†Œê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
        for selector in loading_selectors:
            try:
                await page.wait_for_selector(
                    selector, 
                    timeout=timing_config.get("element_timeout", 10) * 1000
                )
                break
            except PlaywrightTimeoutError:
                continue
        
        # ì¶”ê°€ ëŒ€ê¸°
        action_delay = timing_config.get("action_delay", 1)
        await asyncio.sleep(action_delay)
    
    async def _calculate_backoff(self, attempt: int, site: str, error: str) -> float:
        """ë°±ì˜¤í”„ ì‹œê°„ ê³„ì‚°"""
        retry_config = self.config.crawler.retry
        
        # ê¸°ë³¸ ì§€ìˆ˜ ë°±ì˜¤í”„
        base_delay = retry_config["initial_delay"]
        multiplier = retry_config["backoff_multiplier"]
        max_delay = retry_config["max_delay"]
        
        backoff_time = min(base_delay * (multiplier ** attempt), max_delay)
        
        # ì°¨ë‹¨ ê°ì§€ ì‹œ ì¶”ê°€ ëŒ€ê¸°
        if "ì°¨ë‹¨" in error or "block" in error.lower():
            backoff_time *= 2
            
            # QPS ê°ì†
            current_qps = self.config.get_rate_limit(site)
            new_qps = current_qps * 0.5
            self.rate_limiter.update_qps(site, new_qps)
        
        # ëœë¤ ì§€í„° ì¶”ê°€ (Â±20%)
        jitter = random.uniform(0.8, 1.2)
        return backoff_time * jitter
    
    async def _is_started(self) -> bool:
        """í´ë¼ì´ì–¸íŠ¸ ì‹œì‘ ì—¬ë¶€ í™•ì¸"""
        return self.playwright is not None and self.browser is not None
    
    def get_stats(self) -> Dict[str, Any]:
        """í†µê³„ ë°˜í™˜"""
        total = self.stats["total_requests"]
        if total == 0:
            return self.stats
        
        return {
            **self.stats,
            "success_rate": self.stats["successful_requests"] / total,
            "failure_rate": self.stats["failed_requests"] / total,
            "blocking_rate": self.stats["blocked_requests"] / total
        }
    
    def reset_stats(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "blocked_requests": 0
        }


# ì „ì—­ í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤
_http_client = None


async def get_http_client() -> HttpClient:
    """ì „ì—­ HTTP í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
    global _http_client
    
    if _http_client is None:
        _http_client = HttpClient()
        await _http_client.start()
    
    return _http_client


async def fetch_page(url: str, site: str, 
                    parser_config: Optional[Dict[str, Any]] = None,
                    max_retries: Optional[int] = None,
                    custom_headers: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
    """í˜ì´ì§€ í¬ë¡¤ë§ (í¸ì˜ í•¨ìˆ˜)"""
    client = await get_http_client()
    return await client.fetch(url, site, parser_config, max_retries, custom_headers)


async def close_http_client():
    """ì „ì—­ HTTP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ"""
    global _http_client
    if _http_client:
        await _http_client.close()
        _http_client = None


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    async def test_http_client():
        async with HttpClient() as client:
            try:
                result = await client.fetch(
                    "https://httpbin.org/html", 
                    "test_site"
                )
                print(f"ì„±ê³µ: {result['title']}")
                print(f"í†µê³„: {client.get_stats()}")
                
            except Exception as e:
                print(f"ì‹¤íŒ¨: {e}")
    
    asyncio.run(test_http_client())
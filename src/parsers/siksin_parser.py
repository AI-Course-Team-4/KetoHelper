"""
ğŸ½ï¸ ì‹ì‹ (Siksin) íŒŒì„œ êµ¬í˜„
- BaseParser êµ¬í˜„ì²´
- ì‹ì‹  ì‚¬ì´íŠ¸ ì „ìš© íŒŒì‹± ë¡œì§
- ê²€ìƒ‰ ë° ìƒì„¸ ì •ë³´ ì¶”ì¶œ
"""

import re
import urllib.parse
from typing import List, Dict, Any, Optional
from bs4 import BeautifulSoup

from .base_parser import BaseParser, ParseResult, SearchResult
from ..models import RestaurantCreate, MenuCreate
from ..utils.text_utils import normalize_text, extract_price


class SiksinParser(BaseParser):
    """ì‹ì‹  íŒŒì„œ"""
    
    def __init__(self, http_client=None):
        super().__init__("siksin", http_client)
        self.base_url = self.site_config.get('base_url', 'https://www.siksin.com')
    
    async def search(self, keyword: str, page: int = 1) -> SearchResult:
        """ì‹ë‹¹ ê²€ìƒ‰"""
        try:
            # ê²€ìƒ‰ URL ìƒì„±
            search_url = self._build_search_url(keyword, page)
            self.logger.info(f"ì‹ì‹  ê²€ìƒ‰: {keyword} (í˜ì´ì§€ {page})")
            
            # í˜ì´ì§€ í¬ë¡¤ë§
            content = await self.fetch_page(search_url)
            if not content:
                return SearchResult(
                    restaurants=[],
                    total_found=0,
                    page=page,
                    has_next_page=False,
                    metadata={'error': 'í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨'}
                )
            
            # ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±
            return self._parse_search_results(content, keyword, page)
            
        except Exception as e:
            self.logger.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {keyword} - {e}")
            return SearchResult(
                restaurants=[],
                total_found=0,
                page=page,
                has_next_page=False,
                metadata={'error': str(e)}
            )
    
    def _build_search_url(self, keyword: str, page: int = 1) -> str:
        """ê²€ìƒ‰ URL ìƒì„±"""
        # URL ì¸ì½”ë”©
        encoded_keyword = urllib.parse.quote(keyword)
        
        # ê²€ìƒ‰ URL íŒ¨í„´ì—ì„œ ìƒì„±
        url_pattern = self.search_config.get('url_pattern')
        if url_pattern:
            return url_pattern.format(keyword=encoded_keyword, page=page)
        else:
            # ê¸°ë³¸ íŒ¨í„´
            return f"{self.base_url}/search?query={encoded_keyword}&page={page}"
    
    def _parse_search_results(self, content: str, keyword: str, page: int) -> SearchResult:
        """ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±"""
        soup = BeautifulSoup(content, 'html.parser')
        restaurants = []
        
        try:
            # ì‹ë‹¹ ëª©ë¡ ì»¨í…Œì´ë„ˆ
            list_selector = self.search_config.get('selectors', {}).get('restaurant_list', '.restaurant-item')
            restaurant_elements = soup.select(list_selector)
            
            self.logger.debug(f"ê²€ìƒ‰ ê²°ê³¼ {len(restaurant_elements)}ê°œ ë°œê²¬")
            
            for element in restaurant_elements:
                try:
                    restaurant_data = self._extract_search_item_data(element)
                    if restaurant_data and restaurant_data.get('name'):
                        
                        # ì •ê·œí™”
                        normalized_data = self.normalize_restaurant_data(restaurant_data, restaurant_data.get('source_url', ''))
                        
                        # ê²€ì¦
                        errors = self.validate_restaurant_data(normalized_data)
                        if not errors:
                            restaurant = RestaurantCreate(**normalized_data)
                            restaurants.append(restaurant)
                            self.stats["restaurants_parsed"] += 1
                        else:
                            self.logger.warning(f"ê²€ì¦ ì‹¤íŒ¨: {errors}")
                            
                except Exception as e:
                    self.logger.warning(f"ê°œë³„ ì‹ë‹¹ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    self.stats["parsing_errors"] += 1
                    continue
            
            # ë‹¤ìŒ í˜ì´ì§€ ì—¬ë¶€ í™•ì¸
            has_next = self._has_next_page(soup)
            
            # ì „ì²´ ê²°ê³¼ ìˆ˜ ì¶”ì •
            total_found = len(restaurants) + (page - 1) * 20  # í˜ì´ì§€ë‹¹ 20ê°œ ê°€ì •
            if has_next:
                total_found += 20  # ìµœì†Œ ë‹¤ìŒ í˜ì´ì§€ ì¡´ì¬
            
            return SearchResult(
                restaurants=restaurants,
                total_found=total_found,
                page=page,
                has_next_page=has_next,
                metadata={
                    'keyword': keyword,
                    'found_count': len(restaurants),
                    'parsing_errors': self.stats["parsing_errors"]
                }
            )
            
        except Exception as e:
            self.logger.error(f"ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return SearchResult(
                restaurants=[],
                total_found=0,
                page=page,
                has_next_page=False,
                metadata={'error': str(e)}
            )
    
    def _extract_search_item_data(self, element) -> Dict[str, Any]:
        """ê²€ìƒ‰ ê²°ê³¼ ê°œë³„ í•­ëª© ë°ì´í„° ì¶”ì¶œ"""
        selectors = self.search_config.get('selectors', {})
        
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        name = self._extract_text_from_element(element, selectors.get('restaurant_name', '.restaurant-name'))
        
        # URL ì¶”ì¶œ
        url_element = element.select_one(selectors.get('restaurant_url', 'a'))
        detail_url = ''
        if url_element:
            href = url_element.get('href', '')
            if href:
                if href.startswith('/'):
                    detail_url = self.base_url + href
                elif href.startswith('http'):
                    detail_url = href
                else:
                    detail_url = f"{self.base_url}/{href}"
        
        # ê¸°íƒ€ ì •ë³´
        address = self._extract_text_from_element(element, selectors.get('restaurant_address', '.address'))
        category = self._extract_text_from_element(element, selectors.get('restaurant_category', '.category'))
        rating_text = self._extract_text_from_element(element, selectors.get('restaurant_rating', '.rating'))
        
        # í‰ì  ì¶”ì¶œ
        rating = None
        if rating_text:
            rating_match = re.search(r'(\d+(?:\.\d+)?)', rating_text)
            if rating_match:
                try:
                    rating = float(rating_match.group(1))
                    if rating > 5:  # 10ì  ë§Œì ì„ 5ì  ë§Œì ìœ¼ë¡œ ë³€í™˜
                        rating = rating / 2
                except ValueError:
                    pass
        
        return {
            'name': name,
            'source_url': detail_url,
            'address_road': address,
            'category': category,
            'rating': rating,
        }
    
    def _extract_text_from_element(self, element, selector: str) -> str:
        """ìš”ì†Œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            if selector:
                sub_element = element.select_one(selector)
                if sub_element:
                    return normalize_text(sub_element.get_text(strip=True))
        except Exception:
            pass
        return ""
    
    def _has_next_page(self, soup: BeautifulSoup) -> bool:
        """ë‹¤ìŒ í˜ì´ì§€ ì¡´ì¬ ì—¬ë¶€"""
        try:
            next_selector = self.search_config.get('selectors', {}).get('next_page', '.pagination .next')
            next_element = soup.select_one(next_selector)
            
            # ë‹¤ìŒ ë²„íŠ¼ì´ ìˆê³  ë¹„í™œì„±í™”ë˜ì§€ ì•Šì•˜ë‹¤ë©´
            if next_element and not next_element.get('class', []):
                return 'disabled' not in next_element.get('class', [])
            
            # í˜ì´ì§€ ë²ˆí˜¸ë¡œ í™•ì¸
            page_selector = self.search_config.get('selectors', {}).get('page_numbers', '.pagination .page-num')
            page_elements = soup.select(page_selector)
            
            return len(page_elements) > 0
            
        except Exception:
            return False
    
    async def parse_restaurant_detail(self, url: str) -> ParseResult:
        """ì‹ë‹¹ ìƒì„¸ ì •ë³´ íŒŒì‹±"""
        try:
            self.logger.info(f"ì‹ë‹¹ ìƒì„¸ íŒŒì‹±: {url}")
            
            # í˜ì´ì§€ í¬ë¡¤ë§
            content = await self.fetch_page(url)
            if not content:
                return ParseResult(
                    success=False,
                    error="í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨"
                )
            
            # ë°ì´í„° ì¶”ì¶œ
            restaurant_data = self.extract_restaurant_data(content, url)
            menu_data = self.extract_menu_data(content, url)
            
            return ParseResult(
                success=True,
                data={
                    'restaurant': restaurant_data,
                    'menus': menu_data
                },
                metadata={
                    'url': url,
                    'menu_count': len(menu_data)
                }
            )
            
        except Exception as e:
            self.logger.error(f"ìƒì„¸ ì •ë³´ íŒŒì‹± ì‹¤íŒ¨: {url} - {e}")
            return ParseResult(
                success=False,
                error=str(e),
                metadata={'url': url}
            )
    
    def extract_restaurant_data(self, content: str, url: str) -> Dict[str, Any]:
        """ì‹ë‹¹ ë°ì´í„° ì¶”ì¶œ"""
        selectors = self.detail_config.get('selectors', {})
        
        # ê¸°ë³¸ ì •ë³´
        name = self.extract_text_by_selector(content, selectors.get('name', 'h1'))
        address_road = self.extract_text_by_selector(content, selectors.get('address', '.address'))
        address_jibun = self.extract_text_by_selector(content, selectors.get('address_jibun', '.jibun-address'))
        phone = self.extract_text_by_selector(content, selectors.get('phone', '.phone'))
        category = self.extract_text_by_selector(content, selectors.get('category', '.category'))
        rating_text = self.extract_text_by_selector(content, selectors.get('rating', '.rating'))
        hours = self.extract_text_by_selector(content, selectors.get('hours', '.hours'))
        
        # í‰ì  ì¶”ì¶œ
        rating = None
        if rating_text:
            rating_match = re.search(r'(\d+(?:\.\d+)?)', rating_text)
            if rating_match:
                try:
                    rating = float(rating_match.group(1))
                    if rating > 5:  # 10ì  ë§Œì ì„ 5ì  ë§Œì ìœ¼ë¡œ ë³€í™˜
                        rating = rating / 2
                except ValueError:
                    pass
        
        # ì¢Œí‘œ ì¶”ì¶œ
        lat, lng = self.extract_coordinates_from_content(content)
        
        # ë¦¬ë·° ìˆ˜ ì¶”ì¶œ
        review_count = 0
        review_text = self.extract_text_by_selector(content, selectors.get('review_count', '.review-count'))
        if review_text:
            review_match = re.search(r'(\d+)', review_text)
            if review_match:
                try:
                    review_count = int(review_match.group(1))
                except ValueError:
                    pass
        
        return {
            'name': name,
            'address_road': address_road,
            'address_jibun': address_jibun,
            'lat': lat,
            'lng': lng,
            'phone': phone,
            'category': category,
            'rating': rating,
            'review_count': review_count,
            'business_hours': hours,
            'source_url': url,
        }
    
    def extract_menu_data(self, content: str, url: str) -> List[Dict[str, Any]]:
        """ë©”ë‰´ ë°ì´í„° ì¶”ì¶œ"""
        selectors = self.detail_config.get('selectors', {})
        menus = []
        
        try:
            soup = BeautifulSoup(content, 'html.parser')
            
            # ë©”ë‰´ ì„¹ì…˜ ì°¾ê¸°
            menu_section_selector = selectors.get('menu_section', '.menu-section')
            menu_sections = soup.select(menu_section_selector)
            
            for section in menu_sections:
                # ë©”ë‰´ í•­ëª©ë“¤
                menu_item_selector = selectors.get('menu_items', '.menu-item')
                menu_items = section.select(menu_item_selector)
                
                for item in menu_items:
                    try:
                        # ë©”ë‰´ëª…
                        name_selector = selectors.get('menu_name', '.menu-name')
                        name_element = item.select_one(name_selector)
                        if not name_element:
                            continue
                        
                        name = normalize_text(name_element.get_text(strip=True))
                        if not name:
                            continue
                        
                        # ê°€ê²©
                        price = None
                        price_selector = selectors.get('menu_price', '.menu-price')
                        price_element = item.select_one(price_selector)
                        if price_element:
                            price_text = price_element.get_text(strip=True)
                            price = extract_price(price_text)
                        
                        # ì„¤ëª…
                        description = ""
                        desc_selector = selectors.get('menu_description', '.menu-description')
                        desc_element = item.select_one(desc_selector)
                        if desc_element:
                            description = normalize_text(desc_element.get_text(strip=True))
                        
                        # ì´ë¯¸ì§€
                        image_url = ""
                        img_element = item.select_one('img')
                        if img_element:
                            src = img_element.get('src', '') or img_element.get('data-src', '')
                            if src:
                                if src.startswith('/'):
                                    image_url = self.base_url + src
                                elif src.startswith('http'):
                                    image_url = src
                        
                        # ëŒ€í‘œ ë©”ë‰´ ì—¬ë¶€ (ì˜ˆ: ì¶”ì²œ, ì¸ê¸°, ì‹œê·¸ë‹ˆì²˜ í‚¤ì›Œë“œ)
                        is_signature = self._is_signature_menu(name, description, item)
                        
                        menu_data = {
                            'name': name,
                            'price': price,
                            'description': description,
                            'image_url': image_url,
                            'is_signature': is_signature,
                            'currency': 'KRW'
                        }
                        
                        # ê²€ì¦
                        menu_errors = self.validate_menu_data(menu_data)
                        if not menu_errors:
                            menus.append(menu_data)
                            self.stats["menus_parsed"] += 1
                        
                    except Exception as e:
                        self.logger.warning(f"ê°œë³„ ë©”ë‰´ íŒŒì‹± ì‹¤íŒ¨: {e}")
                        continue
                        
        except Exception as e:
            self.logger.error(f"ë©”ë‰´ ì„¹ì…˜ íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        return menus
    
    def _is_signature_menu(self, name: str, description: str, element) -> bool:
        """ëŒ€í‘œ ë©”ë‰´ ì—¬ë¶€ íŒë‹¨"""
        # í‚¤ì›Œë“œ ê¸°ë°˜ íŒë‹¨
        signature_keywords = ['ì¶”ì²œ', 'ì¸ê¸°', 'ì‹œê·¸ë‹ˆì²˜', 'ëŒ€í‘œ', 'ë² ìŠ¤íŠ¸', 'íŠ¹ì„ ']
        text = f"{name} {description}".lower()
        
        for keyword in signature_keywords:
            if keyword in text:
                return True
        
        # íŠ¹ë³„í•œ ìŠ¤íƒ€ì¼ì´ë‚˜ ë°°ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
        try:
            # ì¶”ì²œ ë°°ì§€ë‚˜ ì•„ì´ì½˜
            if element.select('.recommend, .popular, .signature, .best'):
                return True
            
            # íŠ¹ë³„í•œ í´ë˜ìŠ¤ëª…
            classes = element.get('class', [])
            for cls in classes:
                if any(keyword in cls.lower() for keyword in ['recommend', 'popular', 'signature', 'best']):
                    return True
                    
        except Exception:
            pass
        
        return False
    
    def get_site_info(self) -> Dict[str, Any]:
        """ì‚¬ì´íŠ¸ ì •ë³´ ë°˜í™˜"""
        return {
            'name': self.site_config.get('display_name', 'ì‹ì‹ '),
            'base_url': self.base_url,
            'trust_rank': self.site_config.get('trust_rank', 1),
            'supported_features': [
                'restaurant_search',
                'restaurant_detail',
                'menu_extraction',
                'rating_extraction',
                'coordinate_extraction'
            ]
        }


# í…ŒìŠ¤íŠ¸ ë° ë””ë²„ê·¸ìš© í•¨ìˆ˜ë“¤
def create_test_parser():
    """í…ŒìŠ¤íŠ¸ìš© íŒŒì„œ ìƒì„±"""
    return SiksinParser()


async def test_search(keyword: str = "ê°•ë‚¨ ë§›ì§‘", page: int = 1):
    """ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    parser = create_test_parser()
    result = await parser.search(keyword, page)
    
    print(f"=== ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: {keyword} ===")
    print(f"ë°œê²¬ëœ ì‹ë‹¹: {len(result.restaurants)}ê°œ")
    print(f"ì „ì²´ ì¶”ì •: {result.total_found}ê°œ")
    print(f"ë‹¤ìŒ í˜ì´ì§€: {result.has_next_page}")
    
    for i, restaurant in enumerate(result.restaurants[:3]):  # ì²˜ìŒ 3ê°œë§Œ
        print(f"\n{i+1}. {restaurant.name}")
        print(f"   ì£¼ì†Œ: {restaurant.address_road}")
        print(f"   ì¹´í…Œê³ ë¦¬: {restaurant.category}")
        print(f"   í‰ì : {restaurant.rating}")
        print(f"   URL: {restaurant.source_url}")
    
    return result


async def test_detail_parsing(url: str):
    """ìƒì„¸ ì •ë³´ íŒŒì‹± í…ŒìŠ¤íŠ¸"""
    parser = create_test_parser()
    result = await parser.parse_restaurant_detail(url)
    
    print(f"=== ìƒì„¸ íŒŒì‹± í…ŒìŠ¤íŠ¸: {url} ===")
    print(f"ì„±ê³µ ì—¬ë¶€: {result.success}")
    
    if result.success and result.data:
        restaurant = result.data.get('restaurant', {})
        menus = result.data.get('menus', [])
        
        print(f"\nì‹ë‹¹ ì •ë³´:")
        print(f"  ì´ë¦„: {restaurant.get('name')}")
        print(f"  ì£¼ì†Œ: {restaurant.get('address_road')}")
        print(f"  ì „í™”: {restaurant.get('phone')}")
        print(f"  ì¢Œí‘œ: {restaurant.get('lat')}, {restaurant.get('lng')}")
        print(f"  í‰ì : {restaurant.get('rating')}")
        
        print(f"\në©”ë‰´ ({len(menus)}ê°œ):")
        for menu in menus[:5]:  # ì²˜ìŒ 5ê°œë§Œ
            print(f"  - {menu['name']}: {menu.get('price', 'ê°€ê²©ë¯¸í‘œì‹œ')}ì›")
            if menu.get('is_signature'):
                print(f"    (ëŒ€í‘œ ë©”ë‰´)")
    
    else:
        print(f"íŒŒì‹± ì‹¤íŒ¨: {result.error}")
    
    return result


if __name__ == "__main__":
    import asyncio
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    async def main():
        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        search_result = await test_search("ê°•ë‚¨ ë§›ì§‘")
        
        # ì²« ë²ˆì§¸ ê²°ê³¼ì˜ ìƒì„¸ ì •ë³´ í…ŒìŠ¤íŠ¸
        if search_result.restaurants:
            first_restaurant = search_result.restaurants[0]
            if first_restaurant.source_url:
                await test_detail_parsing(first_restaurant.source_url)
    
    asyncio.run(main())
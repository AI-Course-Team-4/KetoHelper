#!/usr/bin/env python3
"""
ì™„ì „ ìë™í™” í‚¤í†  í—¬í¼ íŒŒì´í”„ë¼ì¸
1. ê°•ë‚¨ì—­ ì£¼ë³€ ë ˆìŠ¤í† ë‘ 30ê°œ í¬ë¡¤ë§
2. ë©”ë‰´ ë°ì´í„° ìˆ˜ì§‘
3. í‚¤í†  ì ìˆ˜ ìë™ ê³„ì‚°
4. Supabase ì €ì¥
"""

import asyncio
import sys
import json
from pathlib import Path
from typing import List, Dict, Any
from uuid import uuid4
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python íŒ¨ìŠ¤ì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.domain.menu import Menu
from core.domain.restaurant import Restaurant, Address
from services.scorer.keto_scorer import KetoScorer
from services.processor.data_processor import DataProcessor
from services.processor.side_dish_classifier import SideDishClassifier
from services.processor.geocoding_service import GeocodingService
from services.cache.cache_manager import CacheManager
from infrastructure.database.supabase_connection import SupabaseConnection
from config.settings import settings
from config.crawler_config import register_crawlers
from services.crawler.crawler_factory import crawler_factory

async def full_automation_pipeline():
    """ì™„ì „ ìë™í™” í‚¤í†  í—¬í¼ íŒŒì´í”„ë¼ì¸"""
    print("ğŸš€ ì™„ì „ ìë™í™” í‚¤í†  í—¬í¼ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("=" * 60)
    
    # ê²°ê³¼ ì €ì¥ìš©
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = f"data/reports/full_automation_{timestamp}.json"
    
    try:
        # 1ë‹¨ê³„: í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” (ê¸°ì¡´ httpx ë²„ì „, í˜ì´ì§€ ìˆ˜ ëŒ€í­ ì¦ê°€)
        print("\nğŸ•·ï¸  1ë‹¨ê³„: httpx í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” (í˜ì´ì§€ ìˆ˜ ëŒ€í­ ì¦ê°€)")
        register_crawlers()
        crawler = crawler_factory.create('diningcode')
        await crawler.initialize()
        print("âœ… DiningcodeCrawler ì´ˆê¸°í™” ì™„ë£Œ")
        
        # 2ë‹¨ê³„: ê°•ë‚¨ì—­ ì£¼ë³€ ë ˆìŠ¤í† ë‘ ëŒ€ëŸ‰ ìˆ˜ì§‘ (í‚¤ì›Œë“œ + ì§€ì—­ í™•ì¥)
        print("\nğŸ” 2ë‹¨ê³„: ê°•ë‚¨ì—­ ì£¼ë³€ ë ˆìŠ¤í† ë‘ ëŒ€ëŸ‰ í¬ë¡¤ë§")
        
        # ê°•ë‚¨ì—­ ë‹¤ì´ì–´íŠ¸ ê´€ë ¨ í•µì‹¬ í‚¤ì›Œë“œ (2ê°œë§Œ)
        search_keywords = [
            "ë‹¤ì´ì–´íŠ¸ ê°•ë‚¨",
            "ì €íƒ„ê³ ì§€ ê°•ë‚¨"
        ]
        target_count = 50  # ëª©í‘œ 50ê°œ (ì €íƒ„ê³ ì§€ ë ˆìŠ¤í† ë‘ í™•ë³´)
        
        print(f"   ê²€ìƒ‰ì–´: {search_keywords}")
        print(f"   ëª©í‘œ ê°œìˆ˜: {target_count}ê°œ")
        
        # Rate Limiterë¥¼ ë” ë¹ ë¥´ê²Œ ì¡°ì • (ì†ë„ ìµœì í™”)
        from infrastructure.external.rate_limiter import create_conservative_rate_limiter
        crawler.rate_limiter = create_conservative_rate_limiter(0.1)  # 0.1ì´ˆ ê°„ê²©ìœ¼ë¡œ ë¹ ë¥´ê²Œ
        
        # í‚¤ì›Œë“œ í™•ì¥ìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (URL ëª©ë¡)
        restaurant_urls = await crawler.crawl_restaurant_list(
            keywords=search_keywords,
            max_pages=1,  # ê° í‚¤ì›Œë“œë‹¹ 1í˜ì´ì§€ì”© (20ê°œì”©, ë¹ ë¥¸ ì‹¤í–‰)
            target_count=target_count  # ëª©í‘œ ê°œìˆ˜
        )
        
        print(f"âœ… {len(restaurant_urls)}ê°œ ë ˆìŠ¤í† ë‘ URL ê²€ìƒ‰ ì™„ë£Œ")
        
        # 3ë‹¨ê³„: ìƒì„¸ ì •ë³´ í¬ë¡¤ë§ (ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ)
        print(f"\nğŸ“Š 3ë‹¨ê³„: ë ˆìŠ¤í† ë‘ ìƒì„¸ ì •ë³´ í¬ë¡¤ë§ (ë³‘ë ¬ ì²˜ë¦¬)")
        
        crawled_data = []
        successful_crawls = 0
        
        # ë³‘ë ¬ ì²˜ë¦¬ë¡œ 5ê°œì”© ë™ì‹œì— í¬ë¡¤ë§
        batch_size = 5
        for batch_start in range(0, len(restaurant_urls), batch_size):
            batch_end = min(batch_start + batch_size, len(restaurant_urls))
            batch_urls = restaurant_urls[batch_start:batch_end]
            
            print(f"\nğŸ”„ ë°°ì¹˜ {batch_start//batch_size + 1}: {len(batch_urls)}ê°œ ì‹ë‹¹ ë³‘ë ¬ í¬ë¡¤ë§ ì¤‘...")
            
            # ë³‘ë ¬ë¡œ í¬ë¡¤ë§
            tasks = [crawler.crawl_restaurant_detail(url) for url in batch_urls]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ê²°ê³¼ ì²˜ë¦¬
            for i, (url, result) in enumerate(zip(batch_urls, results)):
                try:
                    if isinstance(result, Exception):
                        print(f"   âŒ {url}: {result}")
                        continue
                        
                    if result and result.success:
                        crawled_data.append(result.data)
                        successful_crawls += 1
                        
                        menu_count = len(result.data.get('menus', []))
                        restaurant_name = result.data.get('restaurant', {}).get('name', 'Unknown')
                        print(f"   âœ… {restaurant_name}: {menu_count}ê°œ ë©”ë‰´")
                    else:
                        error_msg = result.error if result else "ìƒì„¸ ì •ë³´ ì—†ìŒ"
                        print(f"   âŒ {url}: {error_msg}")
                        
                except Exception as e:
                    print(f"   âŒ {url}: {e}")
            
            # ì§„í–‰ë¥  í‘œì‹œ
            print(f"ğŸ“ˆ ì§„í–‰ë¥ : {batch_end}/{len(restaurant_urls)} ({batch_end/len(restaurant_urls)*100:.1f}%)")
        
        print(f"\nâœ… í¬ë¡¤ë§ ì™„ë£Œ: {successful_crawls}ê°œ ë ˆìŠ¤í† ë‘, ì´ {sum(len(r.get('menus', [])) for r in crawled_data)}ê°œ ë©”ë‰´")
        
        # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(crawled_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“ í¬ë¡¤ë§ ê²°ê³¼ ì €ì¥: {report_file}")
        
        # 4ë‹¨ê³„: Supabase ì—°ê²° ë° ë°ì´í„° ì—…ë¡œë“œ
        print(f"\nğŸ’¾ 4ë‹¨ê³„: Supabase ë°ì´í„° ì—…ë¡œë“œ")
        
        supabase_conn = SupabaseConnection()
        await supabase_conn.initialize()
        supabase = supabase_conn.client
        print("âœ… Supabase ì—°ê²° ì„±ê³µ")
        
        # 5ë‹¨ê³„: ë°ì´í„° ì²˜ë¦¬ê¸° ë° í‚¤í†  ìŠ¤ì½”ì–´ëŸ¬ ì´ˆê¸°í™”
        print(f"\nğŸ”§ 5ë‹¨ê³„: ë°ì´í„° ì²˜ë¦¬ê¸° ì´ˆê¸°í™”")
        data_processor = DataProcessor()
        print("âœ… ë°ì´í„° ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        
        print(f"\nğŸ§® 6ë‹¨ê³„: í‚¤í†  ìŠ¤ì½”ì–´ëŸ¬ ì´ˆê¸°í™”")
        scorer = KetoScorer(settings)
        print("âœ… í‚¤í†  ìŠ¤ì½”ì–´ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ")
        
        print(f"\nğŸ½ï¸  7ë‹¨ê³„: ì‚¬ì´ë“œ ë¶„ë¥˜ê¸° ì´ˆê¸°í™”")
        side_classifier = SideDishClassifier(industry="general")
        print("âœ… ì‚¬ì´ë“œ ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        
        print(f"\nğŸ—ºï¸  7.5ë‹¨ê³„: ì§€ì˜¤ì½”ë”© ì„œë¹„ìŠ¤ ì´ˆê¸°í™”")
        cache_manager = CacheManager()
        geocoding_service = GeocodingService(cache_manager)
        print("âœ… ì§€ì˜¤ì½”ë”© ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # 8ë‹¨ê³„: ë ˆìŠ¤í† ë‘ ë°ì´í„° ì—…ë¡œë“œ
        print(f"\nğŸª 8ë‹¨ê³„: ë ˆìŠ¤í† ë‘ ë°ì´í„° ì—…ë¡œë“œ")
        
        restaurant_count = 0
        restaurant_mapping = {}  # ì›ë³¸ ì´ë¦„ â†’ UUID ë§¤í•‘
        geocoding_stats = {"success": 0, "failed": 0}  # ì§€ì˜¤ì½”ë”© í†µê³„
        
        for item in crawled_data:
            restaurant_info = item['restaurant']
            
            try:
                # ì‹ë‹¹ëª… ì „ì²˜ë¦¬ ì ìš©
                cleaned_restaurant_name = data_processor._clean_restaurant_name(restaurant_info['name'])
                
                # ê¸°ì¡´ ë ˆìŠ¤í† ë‘ ì²´í¬ (source_url ê¸°ì¤€)
                source_url = restaurant_info.get('source_url', '')
                existing_restaurant = supabase.table('restaurant').select('id, name').eq('source_url', source_url).execute()
                
                if existing_restaurant.data:
                    # ê¸°ì¡´ ë ˆìŠ¤í† ë‘ì´ ìˆìœ¼ë©´ í•´ë‹¹ ID ì‚¬ìš©
                    restaurant_id = existing_restaurant.data[0]['id']
                    restaurant_name = existing_restaurant.data[0]['name']
                    restaurant_mapping[restaurant_info['name']] = restaurant_id
                    print(f"   ğŸ”„ ê¸°ì¡´ ë ˆìŠ¤í† ë‘ ë°œê²¬: {restaurant_name} (ID: {restaurant_id})")
                else:
                    # ìƒˆ ë ˆìŠ¤í† ë‘ ìƒì„± - ì‹¤ì œ ì§€ì˜¤ì½”ë”© ìˆ˜í–‰
                    address_text = restaurant_info['address']
                    print(f"   ğŸ—ºï¸  ì§€ì˜¤ì½”ë”© ì¤‘: {address_text}")
                    
                    # ì‹¤ì œ ì§€ì˜¤ì½”ë”© ìˆ˜í–‰
                    try:
                        geocoding_result = await geocoding_service.geocode(address_text)
                        
                        if geocoding_result:
                            latitude = geocoding_result['lat']
                            longitude = geocoding_result['lng']
                            addr_norm = geocoding_result['formatted_address']
                            geocoding_stats["success"] += 1
                            print(f"   âœ… ì§€ì˜¤ì½”ë”© ì„±ê³µ: {latitude:.6f}, {longitude:.6f}")
                        else:
                            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ (ê°•ë‚¨ì—­ ì¤‘ì‹¬)
                            latitude = 37.5665
                            longitude = 127.0286
                            addr_norm = None
                            geocoding_stats["failed"] += 1
                            print(f"   âš ï¸  ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
                            
                    except Exception as e:
                        print(f"   âŒ ì§€ì˜¤ì½”ë”© ì—ëŸ¬: {e}")
                        # ê¸°ë³¸ê°’ ì‚¬ìš©
                        latitude = 37.5665
                        longitude = 127.0286
                        addr_norm = None
                        geocoding_stats["failed"] += 1
                    
                    address = Address(
                        addr_road=address_text,
                        latitude=latitude,
                        longitude=longitude
                    )
                    
                    restaurant = Restaurant(
                        name=cleaned_restaurant_name,  # ì „ì²˜ë¦¬ëœ ì´ë¦„ ì‚¬ìš©
                        address=address,
                        phone=restaurant_info.get('phone'),
                        source=restaurant_info.get('source_name', 'diningcode'),
                        source_url=source_url
                    )
                    
                    # DB ì €ì¥ ë°ì´í„° ì¤€ë¹„
                    restaurant_data = {
                        'id': str(restaurant.id),
                        'name': restaurant.name,
                        'addr_road': restaurant.address.addr_road,
                        'lat': restaurant.address.latitude,
                        'lng': restaurant.address.longitude,
                        'source': restaurant_info.get('source_name', 'diningcode'),
                        'source_url': source_url,
                        'representative_menu_name': None,  # ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸
                        'representative_keto_score': None  # ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸
                    }
                    
                    # ì„ íƒì  í•„ë“œ ì¶”ê°€
                    if restaurant.phone:
                        restaurant_data['phone'] = restaurant.phone
                    
                    # Supabaseì— ì €ì¥
                    restaurant_result = supabase.table('restaurant').insert(restaurant_data).execute()
                    restaurant_mapping[restaurant_info['name']] = str(restaurant.id)
                    restaurant_count += 1
                    
                    print(f"   âœ… [{restaurant_count}] {restaurant.name}")
                
            except Exception as e:
                print(f"   âŒ ë ˆìŠ¤í† ë‘ ì €ì¥ ì‹¤íŒ¨: {restaurant_info['name']} - {e}")
                continue
        
        print(f"âœ… ì´ {restaurant_count}ê°œ ë ˆìŠ¤í† ë‘ ì—…ë¡œë“œ ì™„ë£Œ")
        
        # 9ë‹¨ê³„: ë©”ë‰´ ë°ì´í„° ì—…ë¡œë“œ, ì‚¬ì´ë“œ ë¶„ë¥˜ ë° í‚¤í†  ì ìˆ˜ ê³„ì‚°
        print(f"\nğŸ½ï¸  9ë‹¨ê³„: ë©”ë‰´ ì—…ë¡œë“œ, ì‚¬ì´ë“œ ë¶„ë¥˜ ë° í‚¤í†  ì ìˆ˜ ê³„ì‚°")
        
        menu_count = 0
        keto_score_count = 0
        score_stats = []
        side_stats = {"side": 0, "main": 0}
        
        for item in crawled_data:
            restaurant_info = item['restaurant']
            restaurant_name = restaurant_info['name']
            
            # ë ˆìŠ¤í† ë‘ ID ì°¾ê¸°
            if restaurant_name not in restaurant_mapping:
                print(f"   âš ï¸  ë ˆìŠ¤í† ë‘ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {restaurant_name}")
                continue
                
            restaurant_id = restaurant_mapping[restaurant_name]
            
            # ë ˆìŠ¤í† ë‘ì˜ ëª¨ë“  ë©”ë‰´ ê°€ê²© ìˆ˜ì§‘ (ì‚¬ì´ë“œ ë¶„ë¥˜ìš©)
            restaurant_prices = [menu.get('price') for menu in item.get('menus', [])]
            
            # ë©”ë‰´ë“¤ ì²˜ë¦¬
            for menu_info in item.get('menus', []):
                try:
                    # ë©”ë‰´ëª… ì „ì²˜ë¦¬ ì ìš©
                    cleaned_menu_name = data_processor._clean_menu_name(menu_info['name'])
                    
                    # ì „ì²˜ë¦¬ëœ ë©”ë‰´ëª…ì´ ë¹„ì–´ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
                    if not cleaned_menu_name or len(cleaned_menu_name.strip()) == 0:
                        print(f"   âš ï¸  ë©”ë‰´ëª…ì´ ì „ì²˜ë¦¬ í›„ ë¹„ì–´ìˆìŒ: '{menu_info['name']}', ê±´ë„ˆë›°ê¸°")
                        continue
                    
                    # ì‚¬ì´ë“œ ë¶„ë¥˜ ìˆ˜í–‰
                    side_result = side_classifier.classify(
                        name=cleaned_menu_name,
                        description=menu_info.get('description'),
                        price=menu_info.get('price'),
                        restaurant_prices=restaurant_prices
                    )
                    
                    # ì¤‘ë³µ ë©”ë‰´ ì²´í¬ ë¨¼ì € (ì „ì²˜ë¦¬ëœ ì´ë¦„ìœ¼ë¡œ)
                    existing_menu = supabase.table('menu').select('id').eq('restaurant_id', restaurant_id).eq('name', cleaned_menu_name).execute()
                    
                    if existing_menu.data:
                        # ê¸°ì¡´ ë©”ë‰´ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ID ì‚¬ìš©í•˜ê³  is_side ì—…ë°ì´íŠ¸
                        menu_id = existing_menu.data[0]['id']
                        
                        # ê¸°ì¡´ ë©”ë‰´ì˜ is_side ê°’ ì—…ë°ì´íŠ¸
                        update_data = {'is_side': side_result.is_side}
                        supabase.table('menu').update(update_data).eq('id', menu_id).execute()
                        
                        print(f"   ğŸ”„ ê¸°ì¡´ ë©”ë‰´ ë°œê²¬ ë° ì—…ë°ì´íŠ¸: {cleaned_menu_name} (ID: {menu_id}, is_side: {side_result.is_side})")
                    else:
                        # ìƒˆ ë©”ë‰´ ìƒì„±
                        menu = Menu(
                            name=cleaned_menu_name,  # ì „ì²˜ë¦¬ëœ ì´ë¦„ ì‚¬ìš©
                            price=menu_info.get('price'),
                            description=menu_info.get('description'),
                            restaurant_id=restaurant_id
                        )
                        menu_id = str(menu.id)
                        
                        # ë©”ë‰´ DB ì €ì¥ (ì‚¬ì´ë“œ ë¶„ë¥˜ ê²°ê³¼ í¬í•¨)
                        menu_data = {
                            'id': menu_id,
                            'name': cleaned_menu_name,  # ì „ì²˜ë¦¬ëœ ì´ë¦„ ì‚¬ìš©
                            'price': menu_info.get('price'),
                            'description': menu_info.get('description'),
                            'restaurant_id': restaurant_id,
                            'currency': 'KRW',
                            'is_side': side_result.is_side
                        }
                        
                        menu_result = supabase.table('menu').insert(menu_data).execute()
                    menu_count += 1
                    
                    # í‚¤í†  ì ìˆ˜ ê³„ì‚°ì„ ìœ„í•œ Menu ê°ì²´ ìƒì„±
                    menu_for_scoring = Menu(
                        name=cleaned_menu_name,  # ì „ì²˜ë¦¬ëœ ì´ë¦„ ì‚¬ìš©
                        price=menu_info.get('price'),
                        description=menu_info.get('description'),
                        restaurant_id=restaurant_id
                    )
                    menu_for_scoring.id = menu_id  # ì‹¤ì œ DB ID ì‚¬ìš©
                    
                    # í‚¤í†  ì ìˆ˜ ê³„ì‚°
                    keto_score = await scorer.calculate_score(menu_for_scoring)
                    
                    # í‚¤í†  ì ìˆ˜ ë°ì´í„° ì¤€ë¹„
                    penalty_keywords = [
                        kw for kw in keto_score.detected_keywords 
                        if any(r.impact < 0 for r in keto_score.reasons if r.keyword == kw)
                    ]
                    bonus_keywords = [
                        kw for kw in keto_score.detected_keywords 
                        if any(r.impact > 0 for r in keto_score.reasons if r.keyword == kw)
                    ]
                    
                    keto_score_data = {
                        'menu_id': menu_id,
                        'score': max(0, min(100, int(keto_score.final_score))),
                        'reasons_json': {
                            'reasons': [
                                {
                                    'rule_id': reason.rule_id,
                                    'keyword': reason.keyword,
                                    'impact': reason.impact,
                                    'explanation': reason.explanation
                                } for reason in keto_score.reasons
                            ],
                            'applied_rules': keto_score.applied_rules,
                            'raw_score': keto_score.raw_score,
                            'final_score': keto_score.final_score,
                            'penalty_keywords': penalty_keywords,
                            'bonus_keywords': bonus_keywords,
                            'confidence': float(keto_score.confidence)
                        },
                        'rule_version': 'v1.0'
                    }
                    
                    # í‚¤í†  ì ìˆ˜ ì¤‘ë³µ ì²´í¬ í›„ ì €ì¥
                    existing_score = supabase.table('keto_scores').select('id').eq('menu_id', menu_id).execute()
                    
                    if existing_score.data:
                        # ê¸°ì¡´ ì ìˆ˜ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
                        score_id = existing_score.data[0]['id']
                        keto_result = supabase.table('keto_scores').update(keto_score_data).eq('id', score_id).execute()
                        print(f"   ğŸ”„ í‚¤í†  ì ìˆ˜ ì—…ë°ì´íŠ¸: {cleaned_menu_name} -> {keto_score.final_score}ì ")
                    else:
                        # ìƒˆë¡œìš´ ì ìˆ˜ ìƒì„±
                        keto_result = supabase.table('keto_scores').insert(keto_score_data).execute()
                        print(f"   âœ… í‚¤í†  ì ìˆ˜ ìƒì„±: {cleaned_menu_name} -> {keto_score.final_score}ì ")
                    keto_score_count += 1
                    score_stats.append(keto_score.final_score)
                    
                    # ì‚¬ì´ë“œ ë¶„ë¥˜ í†µê³„ ì—…ë°ì´íŠ¸
                    if side_result.is_side:
                        side_stats["side"] += 1
                        print(f"   ğŸ¥— ì‚¬ì´ë“œ: {cleaned_menu_name} (ì ìˆ˜: {side_result.side_score}, íƒœê·¸: {side_result.tags[:3]})")
                    else:
                        side_stats["main"] += 1
                        print(f"   ğŸ½ï¸  ë©”ì¸: {cleaned_menu_name} (í‚¤í† : {keto_score.final_score}ì )")
                    
                    # ì§„í–‰ë¥  í‘œì‹œ
                    if menu_count % 20 == 0:
                        print(f"   ğŸ“Š ì§„í–‰ë¥ : {menu_count}ê°œ ë©”ë‰´ ì²˜ë¦¬ ì™„ë£Œ...")
                        
                except Exception as e:
                    print(f"   âŒ ë©”ë‰´/ì ìˆ˜ ì €ì¥ ì‹¤íŒ¨: {menu_info.get('name', 'Unknown')} - {e}")
                    continue
        
        print(f"âœ… ì´ {menu_count}ê°œ ë©”ë‰´, {keto_score_count}ê°œ í‚¤í†  ì ìˆ˜ ì €ì¥ ì™„ë£Œ")
        
        # 9.5ë‹¨ê³„: ë ˆìŠ¤í† ë‘ë³„ ëŒ€í‘œ ë©”ë‰´ ë° í‚¤í†  ì ìˆ˜ ì—…ë°ì´íŠ¸
        print(f"\nğŸ† 9.5ë‹¨ê³„: ë ˆìŠ¤í† ë‘ë³„ ëŒ€í‘œ ë©”ë‰´ ë° í‚¤í†  ì ìˆ˜ ì—…ë°ì´íŠ¸")
        
        for restaurant_id in restaurant_mapping.values():
            try:
                # í•´ë‹¹ ë ˆìŠ¤í† ë‘ì˜ ìµœê³  í‚¤í†  ì ìˆ˜ ë©”ë‰´ ì°¾ê¸°
                # ë¨¼ì € í•´ë‹¹ ë ˆìŠ¤í† ë‘ì˜ ë©”ë‰´ IDë“¤ì„ ê°€ì ¸ì˜¤ê¸°
                menu_ids_result = supabase.table('menu').select('id').eq('restaurant_id', restaurant_id).execute()
                
                if menu_ids_result.data:
                    menu_ids = [menu['id'] for menu in menu_ids_result.data]
                    
                    # í•´ë‹¹ ë©”ë‰´ë“¤ì˜ í‚¤í†  ì ìˆ˜ ì¤‘ ìµœê³ ì  ì°¾ê¸°
                    best_menu_result = supabase.table('keto_scores').select(
                        'menu_id', 'score'
                    ).in_('menu_id', menu_ids).order('score', desc=True).limit(1).execute()
                    
                    if best_menu_result.data:
                        best_score = best_menu_result.data[0]
                        best_menu_id = best_score['menu_id']
                        representative_keto_score = best_score['score']
                        
                        # ìµœê³  ì ìˆ˜ ë©”ë‰´ì˜ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                        menu_name_result = supabase.table('menu').select('name').eq('id', best_menu_id).execute()
                        if menu_name_result.data:
                            representative_menu_name = menu_name_result.data[0]['name']
                        else:
                            representative_menu_name = "ì•Œ ìˆ˜ ì—†ëŠ” ë©”ë‰´"
                    else:
                        representative_menu_name = None
                        representative_keto_score = None
                else:
                    representative_menu_name = None
                    representative_keto_score = None
                
                # ë ˆìŠ¤í† ë‘ ì •ë³´ ì—…ë°ì´íŠ¸
                if representative_menu_name and representative_keto_score is not None:
                    update_result = supabase.table('restaurant').update({
                        'representative_menu_name': representative_menu_name,
                        'representative_keto_score': representative_keto_score
                    }).eq('id', restaurant_id).execute()
                    
                    print(f"   âœ… {representative_menu_name} (ì ìˆ˜: {representative_keto_score})")
                else:
                    print(f"   âš ï¸  ë©”ë‰´ ì—†ìŒ: {restaurant_id}")
                    
            except Exception as e:
                print(f"   âŒ ëŒ€í‘œ ë©”ë‰´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {restaurant_id} - {e}")
        
        # 10ë‹¨ê³„: ìµœì¢… ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ“Š 10ë‹¨ê³„: ìµœì¢… ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        print(f"ğŸª ë ˆìŠ¤í† ë‘: {restaurant_count}ê°œ")
        print(f"ğŸ½ï¸  ë©”ë‰´: {menu_count}ê°œ")
        print(f"ğŸ§® í‚¤í†  ì ìˆ˜: {keto_score_count}ê°œ")
        print(f"ğŸ¥— ì‚¬ì´ë“œ ë©”ë‰´: {side_stats['side']}ê°œ")
        print(f"ğŸ½ï¸  ë©”ì¸ ë©”ë‰´: {side_stats['main']}ê°œ")
        
        # ì§€ì˜¤ì½”ë”© í†µê³„ ì¶œë ¥
        print(f"\nğŸ—ºï¸  ì§€ì˜¤ì½”ë”© í†µê³„:")
        print(f"   ì„±ê³µ: {geocoding_stats['success']}ê°œ")
        print(f"   ì‹¤íŒ¨: {geocoding_stats['failed']}ê°œ")
        if geocoding_stats['success'] + geocoding_stats['failed'] > 0:
            total_geocoding = geocoding_stats['success'] + geocoding_stats['failed']
            success_rate = geocoding_stats['success'] / total_geocoding * 100
            print(f"   ì„±ê³µë¥ : {success_rate:.1f}%")
        
        if menu_count > 0:
            side_percentage = side_stats['side'] / menu_count * 100
            main_percentage = side_stats['main'] / menu_count * 100
            print(f"\nğŸ” ì‚¬ì´ë“œ/ë©”ì¸ ë¶„í¬:")
            print(f"   ì‚¬ì´ë“œ: {side_stats['side']}ê°œ ({side_percentage:.1f}%)")
            print(f"   ë©”ì¸: {side_stats['main']}ê°œ ({main_percentage:.1f}%)")
        
        if score_stats:
            print(f"\nğŸ“ˆ í‚¤í†  ì ìˆ˜ í†µê³„:")
            print(f"   í‰ê· : {sum(score_stats)/len(score_stats):.1f}ì ")
            print(f"   ìµœê³ : {max(score_stats):.1f}ì ")
            print(f"   ìµœì €: {min(score_stats):.1f}ì ")
            
            # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
            categories = {
                "í‚¤í†  ê¶Œì¥ (80ì  ì´ìƒ)": len([s for s in score_stats if s >= 80]),
                "ì¡°ê±´ë¶€ í‚¤í†  (50-79ì )": len([s for s in score_stats if 50 <= s < 80]),
                "í‚¤í†  ì£¼ì˜ (20-49ì )": len([s for s in score_stats if 20 <= s < 50]),
                "í‚¤í†  ë¹„ì¶”ì²œ (20ì  ë¯¸ë§Œ)": len([s for s in score_stats if s < 20])
            }
            
            print(f"\nğŸ·ï¸  ì¹´í…Œê³ ë¦¬ ë¶„í¬:")
            for category, count in categories.items():
                percentage = count / len(score_stats) * 100
                print(f"   {category}: {count}ê°œ ({percentage:.1f}%)")
        
        # 11ë‹¨ê³„: ìƒ˜í”Œ ë°ì´í„° í™•ì¸
        print(f"\nğŸ” 11ë‹¨ê³„: ì €ì¥ëœ ë°ì´í„° ìƒ˜í”Œ í™•ì¸")
        
        # ìƒìœ„ í‚¤í†  ì ìˆ˜ ë©”ë‰´ë“¤ ì¡°íšŒ
        sample_query = """
            id,
            menu:menu_id(name, price, restaurant:restaurant_id(name)),
            score,
            reasons_json
        """
        
        sample_result = supabase.table('keto_scores').select(sample_query).order('score', desc=True).limit(5).execute()
        
        if sample_result.data:
            print("âœ… ìƒìœ„ 5ê°œ í‚¤í†  ì ìˆ˜:")
            for item in sample_result.data:
                menu_info = item.get('menu', {})
                restaurant_info = menu_info.get('restaurant', {})
                menu_name = menu_info.get('name', 'N/A')
                price = menu_info.get('price', 'N/A')
                restaurant_name = restaurant_info.get('name', 'N/A')
                score = item.get('score', 0)
                reasons = item.get('reasons_json', {})
                confidence = reasons.get('confidence', 0)
                
                print(f"   ğŸ“‹ {menu_name} - {restaurant_name}")
                print(f"      ì ìˆ˜: {score}ì  (ì‹ ë¢°ë„: {confidence:.2f})")
                print(f"      ê°€ê²©: {price}ì›")
                print()
        
        print("ğŸ‰ ì™„ì „ ìë™í™” í‚¤í†  í—¬í¼ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print("=" * 60)
        
        # í¬ë¡¤ëŸ¬ ì •ë¦¬
        if hasattr(crawler, 'close'):
            await crawler.close()
        
    except Exception as e:
        print(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        
        # í¬ë¡¤ëŸ¬ ì •ë¦¬ (ì—ëŸ¬ ì‹œì—ë„)
        try:
            if hasattr(crawler, 'close'):
                await crawler.close()
        except:
            pass

if __name__ == "__main__":
    asyncio.run(full_automation_pipeline())

#!/usr/bin/env python3
"""
ğŸ•·ï¸ ì‹ë‹¹ í¬ë¡¤ë§ ì‹œìŠ¤í…œ - MVP v1.0

ì‚¬ìš©ë²•:
    python crawler.py --restaurant "ê°•ë‚¨ ë§›ì§‘" --site siksin
    python crawler.py --restaurant "ê°•ë‚¨ì—­ ë§›ì§‘" --site siksin --max-results 10
    python crawler.py --help
"""

import sys
import asyncio
import click
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.utils.config_loader import get_config
from src.utils.logger import setup_logging, get_logger


@click.group()
@click.option('--config', '-c', type=str, help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
@click.option('--debug', '-d', is_flag=True, help='ë””ë²„ê·¸ ëª¨ë“œ')
@click.pass_context
def cli(ctx, config, debug):
    """ğŸ•·ï¸ ì‹ë‹¹ í¬ë¡¤ë§ ì‹œìŠ¤í…œ - MVP v1.0"""
    
    # ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
    ctx.ensure_object(dict)
    
    # ì„¤ì • ì´ˆê¸°í™”
    try:
        app_config = get_config(config)
        ctx.obj['config'] = app_config
        
        # ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •
        if debug:
            app_config.app.debug = True
        
        # ë¡œê¹… ì„¤ì •
        setup_logging(config)
        
    except Exception as e:
        click.echo(f"âŒ ì„¤ì • ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", err=True)
        sys.exit(1)


@cli.command()
@click.option('--restaurant', '-r', required=True, help='í¬ë¡¤ë§í•  ì‹ë‹¹ëª… (ì˜ˆ: "ê°•ë‚¨ ë§›ì§‘")')
@click.option('--site', '-s', default='siksin', 
              type=click.Choice(['siksin', 'diningcode', 'mangoplate']),
              help='í¬ë¡¤ë§ ëŒ€ìƒ ì‚¬ì´íŠ¸')
@click.option('--max-results', '-m', default=10, help='ìµœëŒ€ ê²°ê³¼ ìˆ˜')
@click.option('--save-raw', is_flag=True, help='ì›ë³¸ HTML ì €ì¥')
@click.pass_context
def crawl(ctx, restaurant, site, max_results, save_raw):
    """ğŸ” ì‹ë‹¹ í¬ë¡¤ë§ ì‹¤í–‰"""
    
    config = ctx.obj['config']
    logger = get_logger("crawler")
    
    click.echo(f"ğŸ•·ï¸ í¬ë¡¤ë§ ì‹œì‘: {restaurant} ({site})")
    click.echo(f"ğŸ“Š ìµœëŒ€ ê²°ê³¼: {max_results}ê°œ")
    
    try:
        # í¬ë¡¤ë§ ì‹¤í–‰ (ë¹„ë™ê¸°)
        result = asyncio.run(
            run_crawling(config, restaurant, site, max_results, save_raw)
        )
        
        # ê²°ê³¼ ì¶œë ¥
        click.echo(f"\nâœ… í¬ë¡¤ë§ ì™„ë£Œ!")
        click.echo(f"   ğŸ“ ì‹ë‹¹: {result['restaurants_found']}ê°œ")
        click.echo(f"   ğŸ½ï¸ ë©”ë‰´: {result['menus_found']}ê°œ")
        click.echo(f"   â±ï¸ ì†Œìš”ì‹œê°„: {result['duration']:.2f}ì´ˆ")
        
        if result['errors']:
            click.echo(f"   âš ï¸ ì—ëŸ¬: {len(result['errors'])}ê±´")
            for error in result['errors'][:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                click.echo(f"      - {error}")
                
    except KeyboardInterrupt:
        click.echo("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        logger.error(f"í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        click.echo(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}", err=True)
        sys.exit(1)


@cli.command()
@click.pass_context
def status(ctx):
    """ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    
    config = ctx.obj['config']
    
    click.echo("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
    click.echo("=" * 50)
    click.echo(f"ì•± ì´ë¦„: {config.app.name}")
    click.echo(f"ë²„ì „: {config.app.version}")
    click.echo(f"ë””ë²„ê·¸ ëª¨ë“œ: {config.app.debug}")
    click.echo(f"ë°ì´í„°ë² ì´ìŠ¤: {config.database.host}:{config.database.port}")
    click.echo(f"ë¡œê·¸ ë ˆë²¨: {config.logging.level}")
    
    click.echo("\nğŸ•·ï¸ í¬ë¡¤ëŸ¬ ì„¤ì •")
    click.echo(f"ë™ì‹œ íƒ­ ìˆ˜: {config.crawler.max_concurrent_tabs}")
    click.echo(f"í˜ì´ì§€ íƒ€ì„ì•„ì›ƒ: {config.crawler.page_timeout}ì´ˆ")
    click.echo(f"ì†ë„ ì œí•œ: {config.crawler.rate_limits}")
    
    # TODO: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
    # TODO: í¬ë¡¤ë§ í†µê³„ í‘œì‹œ


@cli.command()
@click.pass_context  
def config_test(ctx):
    """ğŸ”§ ì„¤ì • íŒŒì¼ í…ŒìŠ¤íŠ¸"""
    
    config = ctx.obj['config']
    
    click.echo("ğŸ”§ ì„¤ì • íŒŒì¼ í…ŒìŠ¤íŠ¸")
    click.echo("=" * 50)
    
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ URL í…ŒìŠ¤íŠ¸
        db_url = config.get_database_url()
        click.echo(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ URL: {db_url}")
        
        # íŒŒì„œ ì„¤ì • í…ŒìŠ¤íŠ¸
        for site in ['siksin']:
            try:
                parser_config = config.get_parser_config(site)
                click.echo(f"âœ… {site} íŒŒì„œ ì„¤ì •: OK")
            except Exception as e:
                click.echo(f"âŒ {site} íŒŒì„œ ì„¤ì •: {e}")
        
        # ì‚¬ìš©ì ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸
        user_agent = config.get_user_agent()
        click.echo(f"âœ… ì‚¬ìš©ì ì—ì´ì „íŠ¸: {user_agent[:50]}...")
        
        click.echo("\nâœ… ëª¨ë“  ì„¤ì •ì´ ì •ìƒì…ë‹ˆë‹¤!")
        
    except Exception as e:
        click.echo(f"âŒ ì„¤ì • í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}", err=True)
        sys.exit(1)


@cli.command()
@click.option('--site', '-s', default='all', help='í†µê³„ë¥¼ ë³¼ ì‚¬ì´íŠ¸ (all, siksin, etc.)')
@click.pass_context
def stats(ctx, site):
    """ğŸ“ˆ í¬ë¡¤ë§ í†µê³„ ì¡°íšŒ"""
    
    click.echo(f"ğŸ“ˆ í¬ë¡¤ë§ í†µê³„ ({site})")
    click.echo("=" * 50)
    
    # TODO: ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í†µê³„ ì¡°íšŒ
    click.echo("ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    click.echo("ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ í›„ êµ¬í˜„ ì˜ˆì •")


async def run_crawling(config, restaurant_keyword, site, max_results, save_raw):
    """ì‹¤ì œ í¬ë¡¤ë§ ë¡œì§ (ë¹„ë™ê¸°)"""
    import time
    
    logger = get_logger("crawler")
    start_time = time.time()
    
    # TODO: ì‹¤ì œ í¬ë¡¤ë§ ì—”ì§„ êµ¬í˜„ í›„ êµì²´
    logger.info(f"í¬ë¡¤ë§ ì‹œë®¬ë ˆì´ì…˜: {restaurant_keyword} ({site})")
    
    # ì‹œë®¬ë ˆì´ì…˜: ê°€ì§œ ê²°ê³¼ ë°˜í™˜
    await asyncio.sleep(2)  # í¬ë¡¤ë§ ì‹œë®¬ë ˆì´ì…˜
    
    duration = time.time() - start_time
    
    return {
        "restaurants_found": 5,
        "menus_found": 25,
        "duration": duration,
        "errors": []
    }


if __name__ == "__main__":
    # CLI ì‹¤í–‰
    cli()
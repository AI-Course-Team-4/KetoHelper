#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì™„ì „í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (í‚¤ì›Œë“œ + ë²¡í„°)
"""

import os
import json
import numpy as np
from typing import List, Dict, Any
from dotenv import load_dotenv
from supabase import create_client
from openai import OpenAI

# í™˜ê²½ì„¤ì •
load_dotenv('../.env')
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")

def get_query_embedding(query: str) -> List[float]:
    """ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±"""
    openai_client = OpenAI(api_key=OPENAI_API_KEY)
    response = openai_client.embeddings.create(
        model="text-embedding-3-small",
        input=query
    )
    return response.data[0].embedding

def parse_embedding_string(embedding_str: str) -> List[float]:
    """JSON ë¬¸ìì—´ë¡œ ì €ì¥ëœ ì„ë² ë”©ì„ íŒŒì‹±"""
    try:
        if isinstance(embedding_str, str):
            return json.loads(embedding_str)
        return embedding_str
    except:
        return []

def cosine_similarity(a: List[float], b: List[float]) -> float:
    """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
    if not a or not b or len(a) != len(b):
        return 0.0
    
    a_np = np.array(a)
    b_np = np.array(b)
    
    dot_product = np.dot(a_np, b_np)
    norm_a = np.linalg.norm(a_np)
    norm_b = np.linalg.norm(b_np)
    
    if norm_a == 0 or norm_b == 0:
        return 0.0
    
    return dot_product / (norm_a * norm_b)

def test_keyword_search(client, query: str, limit: int = 10) -> List[Dict]:
    """í‚¤ì›Œë“œ ê²€ìƒ‰"""
    try:
        result = client.table("recipes_keto_enhanced").select("*").text_search("blob", query).execute()
        if result.data:
            return [{'id': item['id'], 'title': item['title'], 'blob': item['blob'], 'type': 'keyword', 'score': 0.8} for item in result.data[:limit]]
        return []
    except:
        return []

def test_vector_search(client, query: str, limit: int = 10) -> List[Dict]:
    """ë²¡í„° ê²€ìƒ‰"""
    try:
        query_embedding = get_query_embedding(query)
        result = client.table("recipes_keto_enhanced").select("id, title, blob, embedding").execute()
        
        similarities = []
        for recipe in result.data:
            embedding_str = recipe.get('embedding', '')
            parsed_embedding = parse_embedding_string(embedding_str)
            
            if parsed_embedding and len(parsed_embedding) == len(query_embedding):
                similarity = cosine_similarity(query_embedding, parsed_embedding)
                similarities.append({
                    'id': recipe.get('id'),
                    'title': recipe.get('title', ''),
                    'blob': recipe.get('blob', ''),
                    'type': 'vector',
                    'score': similarity
                })
        
        similarities.sort(key=lambda x: x['score'], reverse=True)
        return similarities[:limit]
    except:
        return []

def test_hybrid_search(client, query: str, limit: int = 5):
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í‚¤ì›Œë“œ + ë²¡í„°)"""
    print(f"\nğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: '{query}'")
    
    # í‚¤ì›Œë“œ ê²€ìƒ‰
    keyword_results = test_keyword_search(client, query, limit)
    print(f"âœ… í‚¤ì›Œë“œ ê²°ê³¼: {len(keyword_results)}ê°œ")
    
    # ë²¡í„° ê²€ìƒ‰
    vector_results = test_vector_search(client, query, limit)
    print(f"âœ… ë²¡í„° ê²°ê³¼: {len(vector_results)}ê°œ")
    
    # ê²°ê³¼ í•©ì¹˜ê¸°
    all_results = {}
    
    # í‚¤ì›Œë“œ ê²°ê³¼ ì¶”ê°€
    for item in keyword_results:
        all_results[item['id']] = {
            'id': item['id'],
            'title': item['title'],
            'blob': item['blob'],
            'keyword_score': item['score'],
            'vector_score': 0.0
        }
    
    # ë²¡í„° ê²°ê³¼ ì¶”ê°€/ì—…ë°ì´íŠ¸
    for item in vector_results:
        if item['id'] in all_results:
            all_results[item['id']]['vector_score'] = item['score']
        else:
            all_results[item['id']] = {
                'id': item['id'],
                'title': item['title'],
                'blob': item['blob'],
                'keyword_score': 0.0,
                'vector_score': item['score']
            }
    
    # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
    for item in all_results.values():
        keyword_score = item['keyword_score']
        vector_score = item['vector_score']
        # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ = 0.4 * í‚¤ì›Œë“œ + 0.6 * ë²¡í„°
        item['hybrid_score'] = 0.4 * keyword_score + 0.6 * vector_score
    
    # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    hybrid_results = sorted(all_results.values(), key=lambda x: x['hybrid_score'], reverse=True)
    
    print(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²°ê³¼: {len(hybrid_results)}ê°œ")
    for i, item in enumerate(hybrid_results[:limit], 1):
        keyword_score = item['keyword_score'] * 100
        vector_score = item['vector_score'] * 100
        hybrid_score = item['hybrid_score'] * 100
        print(f"  {i}. {item['title'][:40]}...")
        print(f"     í‚¤ì›Œë“œ: {keyword_score:.1f}% | ë²¡í„°: {vector_score:.1f}% | í•˜ì´ë¸Œë¦¬ë“œ: {hybrid_score:.1f}%")

def test_all_searches():
    """ëª¨ë“  ê²€ìƒ‰ ë°©ì‹ í…ŒìŠ¤íŠ¸"""
    print("=== ì™„ì „í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ===")
    
    client = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = ["ê¹€ë°¥", "í‚¤í†  ì¼€ì´í¬", "ì €íƒ„ìˆ˜ ë””ì €íŠ¸", "ê³„ë€ ìš”ë¦¬", "ë‹¤ì´ì–´íŠ¸ ìŒì‹"]
    
    for query in test_queries:
        print(f"\n{'='*60}")
        print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
        print('='*60)
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        test_hybrid_search(client, query, 3)

if __name__ == "__main__":
    test_all_searches()

#!/usr/bin/env python3
"""
Enhanced Blob Approach - Supabase êµ¬í˜„
ë” í’ë¶€í•œ ì½˜í…ì¸ ë¡œ ì„ë² ë”©í•˜ì—¬ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
"""

import os
import json
import time
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from supabase import create_client, Client
from openai import OpenAI

# .env íŒŒì¼ ë¡œë“œ
load_dotenv('../.env')

class EnhancedBlobApproachSupabase:
    """Enhanced Blob ë°©ì‹ - ë” í’ë¶€í•œ ì½˜í…ì¸ ë¡œ ì„ë² ë”©"""

    def __init__(self):
        self.approach_name = "enhanced_blob"
        self.table_name = "recipes_enhanced_blob"
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        self.openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.embedding_model = 'text-embedding-3-small'
        self.embedding_dimension = 1536

        # Supabase í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        self.supabase_url = os.getenv('SUPABASE_URL')
        self.supabase_key = os.getenv('SUPABASE_ANON_KEY')

        if not self.supabase_url or not self.supabase_key:
            raise ValueError("SUPABASE_URLê³¼ SUPABASE_ANON_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        self.supabase: Client = create_client(self.supabase_url, self.supabase_key)

    def normalize_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ê·œí™”"""
        if not text:
            return ""

        # ê¸°ë³¸ ì •ê·œí™”
        text = text.strip()
        text = ' '.join(text.split())  # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ

        # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
        replacements = {
            'Â·': ' ', 'âˆ™': ' ', 'â€»': '', 'â˜…': '', 'â™¥': '', 'â™¡': '',
            '[': '', ']': '', '(': '', ')': '', '{': '', '}': '',
            '!': '', '?': '', '~': '', '`': '', '"': '', "'": ''
        }

        for old, new in replacements.items():
            text = text.replace(old, new)

        return text.strip()

    def _llm_enhance_content(self, recipe: Dict[str, Any]) -> Dict[str, Any]:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì½˜í…ì¸  ê°•í™” ë° ì •ê·œí™”"""
        try:
            # ì›ë³¸ ë°ì´í„° ìˆ˜ì§‘
            title = recipe.get('title', '')
            description = recipe.get('summary', '')
            tags = recipe.get('tags', [])
            ingredients = recipe.get('ingredients', [])
            
            # íƒœê·¸ ì •ê·œí™”
            if isinstance(tags, str):
                try:
                    tags = json.loads(tags)
                except:
                    tags = []
            
            # ì¬ë£Œ ì •ë³´ ì •ê·œí™”
            ingredients_text = ""
            if isinstance(ingredients, list):
                ingredients_text = ", ".join([str(ing) for ing in ingredients])
            elif isinstance(ingredients, str):
                ingredients_text = ingredients

            # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = f"""
ë‹¤ìŒ ë ˆì‹œí”¼ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

ì œëª©: {title}
ì„¤ëª…: {description}
íƒœê·¸: {tags}
ì¬ë£Œ: {ingredients_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”í•´ì£¼ì„¸ìš”:
1. ìš”ë¦¬ ì¢…ë¥˜ (í•œì‹, ì¤‘ì‹, ì¼ì‹, ì–‘ì‹, ê¸°íƒ€)
2. ìš”ë¦¬ ë°©ë²• (êµ½ê¸°, ë“ì´ê¸°, ë³¶ê¸°, íŠ€ê¸°ê¸°, ì°œ, ê¸°íƒ€)
3. ìŒì‹ ì¹´í…Œê³ ë¦¬ (ë©”ì¸ìš”ë¦¬, ê°„ì‹, ë””ì €íŠ¸, ìŒë£Œ, ê¸°íƒ€)
4. ë§› í”„ë¡œí•„ (ë‹¬ì½¤í•¨, ë§¤ì›€, ë‹´ë°±í•¨, ì§ ë§›, ì‹ ë§›, ê¸°íƒ€)
5. ì˜ì–‘ íŠ¹ì„± (ê³ ë‹¨ë°±, ì €íƒ„ìˆ˜, ì €ì¹¼ë¡œë¦¬, ê³ ì„¬ìœ , ê¸°íƒ€)
6. ì •ê·œí™”ëœ ì œëª© (ë§ˆì¼€íŒ… ë‹¨ì–´ ì œê±°)
7. ì •ê·œí™”ëœ ì„¤ëª… (í•µì‹¬ ë‚´ìš©ë§Œ)
8. ì •ê·œí™”ëœ ì¬ë£Œ (ì£¼ìš” ì¬ë£Œë§Œ)
9. ì •ê·œí™”ëœ íƒœê·¸ (í•µì‹¬ í‚¤ì›Œë“œë§Œ)

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "cuisine_type": "ìš”ë¦¬ ì¢…ë¥˜",
    "cooking_method": "ìš”ë¦¬ ë°©ë²•", 
    "dish_category": "ìŒì‹ ì¹´í…Œê³ ë¦¬",
    "flavor_profile": "ë§› í”„ë¡œí•„",
    "nutrition_type": "ì˜ì–‘ íŠ¹ì„±",
    "normalized_title": "ì •ê·œí™”ëœ ì œëª©",
    "normalized_description": "ì •ê·œí™”ëœ ì„¤ëª…",
    "normalized_ingredients": ["ì •ê·œí™”ëœ", "ì¬ë£Œ", "ëª©ë¡"],
    "normalized_tags": ["ì •ê·œí™”ëœ", "íƒœê·¸", "ëª©ë¡"]
}}
"""

            # LLM í˜¸ì¶œ
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë ˆì‹œí”¼ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë§ˆì¼€íŒ… ë‹¨ì–´ë¥¼ ì œê±°í•˜ê³  í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=1000
            )

            # ì‘ë‹µ íŒŒì‹±
            llm_result = response.choices[0].message.content
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                enhanced_data = json.loads(llm_result)
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
                enhanced_data = {
                    "cuisine_type": "ê¸°íƒ€",
                    "cooking_method": "ê¸°íƒ€",
                    "dish_category": "ê¸°íƒ€",
                    "flavor_profile": "ê¸°íƒ€",
                    "nutrition_type": "ê¸°íƒ€",
                    "normalized_title": self.normalize_text(title),
                    "normalized_description": self.normalize_text(description),
                    "normalized_ingredients": [self.normalize_text(ing) for ing in ingredients[:5]] if isinstance(ingredients, list) else [],
                    "normalized_tags": [self.normalize_text(tag) for tag in tags[:5]] if isinstance(tags, list) else []
                }

            # ì•½ê°„ì˜ ë”œë ˆì´ (API ì œí•œ ê³ ë ¤)
            time.sleep(0.1)
            
            return enhanced_data

        except Exception as e:
            print(f"LLM ì½˜í…ì¸  ê°•í™” ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "cuisine_type": "ê¸°íƒ€",
                "cooking_method": "ê¸°íƒ€", 
                "dish_category": "ê¸°íƒ€",
                "flavor_profile": "ê¸°íƒ€",
                "nutrition_type": "ê¸°íƒ€",
                "normalized_title": self.normalize_text(recipe.get('title', '')),
                "normalized_description": self.normalize_text(recipe.get('summary', '')),
                "normalized_ingredients": [],
                "normalized_tags": []
            }

    def create_enhanced_blob(self, recipe: Dict[str, Any], enhanced_data: Dict[str, Any]) -> str:
        """Enhanced Blob ì½˜í…ì¸  ìƒì„±"""
        blob_parts = []
        
        # 1. ìš”ë¦¬ íŠ¹ì„±ë“¤
        characteristics = []
        if enhanced_data.get('cuisine_type'):
            characteristics.append(enhanced_data['cuisine_type'])
        if enhanced_data.get('cooking_method'):
            characteristics.append(enhanced_data['cooking_method'])
        if enhanced_data.get('dish_category'):
            characteristics.append(enhanced_data['dish_category'])
        if enhanced_data.get('flavor_profile'):
            characteristics.append(enhanced_data['flavor_profile'])
        if enhanced_data.get('nutrition_type'):
            characteristics.append(enhanced_data['nutrition_type'])
        
        if characteristics:
            blob_parts.append(" ".join(characteristics))
        
        # 2. ì •ê·œí™”ëœ ì œëª©
        if enhanced_data.get('normalized_title'):
            blob_parts.append(f"ì œëª©: {enhanced_data['normalized_title']}")
        
        # 3. ì •ê·œí™”ëœ ì„¤ëª…
        if enhanced_data.get('normalized_description'):
            blob_parts.append(f"ì„¤ëª…: {enhanced_data['normalized_description']}")
        
        # 4. ì •ê·œí™”ëœ ì¬ë£Œ
        if enhanced_data.get('normalized_ingredients'):
            ingredients_text = ", ".join(enhanced_data['normalized_ingredients'])
            blob_parts.append(f"ì£¼ìš” ì¬ë£Œ: {ingredients_text}")
        
        # 5. ì •ê·œí™”ëœ íƒœê·¸
        if enhanced_data.get('normalized_tags'):
            tags_text = ", ".join(enhanced_data['normalized_tags'])
            blob_parts.append(f"íƒœê·¸: {tags_text}")
        
        return "\n".join(blob_parts)

    def _get_openai_embedding(self, text: str) -> List[float]:
        """OpenAI text-embedding-3-smallë¡œ ì„ë² ë”© ìƒì„±"""
        try:
            response = self.openai_client.embeddings.create(
                model=self.embedding_model,
                input=text,
                encoding_format="float"
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"OpenAI embedding error: {e}")
            return [0.0] * self.embedding_dimension

    def save_recipe_embedding(self, recipe: Dict[str, Any]) -> bool:
        """Enhanced Blob ë°©ì‹ìš© ë ˆì‹œí”¼ ì„ë² ë”© ì €ì¥"""
        try:
            # LLM ì½˜í…ì¸  ê°•í™”
            enhanced_data = self._llm_enhance_content(recipe)
            
            # Enhanced Blob ìƒì„±
            enhanced_blob = self.create_enhanced_blob(recipe, enhanced_data)
            
            # OpenAI text-embedding-3-smallë¡œ ì„ë² ë”© ìƒì„±
            embedding = self._get_openai_embedding(enhanced_blob)
            
            # Enhanced Blob ë°©ì‹ ì „ìš© ë°ì´í„° êµ¬ì¡°
            data = {
                'recipe_id': recipe.get('source_recipe_id', ''),
                'title': recipe.get('title', ''),
                'description': recipe.get('summary', ''),
                'tags': recipe.get('tags', []),
                'ingredients': recipe.get('ingredients', []),
                'cooking_method': enhanced_data.get('cooking_method', ''),
                'enhanced_blob': enhanced_blob,
                'embedding': embedding,
                'metadata': {
                    'approach': self.approach_name,
                    'blob_length': len(enhanced_blob),
                    'has_title': bool(recipe.get('title', '').strip()),
                    'ingredient_count': len(recipe.get('ingredients', [])),
                    'enhanced_data': enhanced_data
                }
            }

            result = self.supabase.table(self.table_name).upsert(data, on_conflict='recipe_id').execute()
            return True

        except Exception as e:
            print(f"Error saving recipe {recipe.get('source_recipe_id', 'unknown')}: {e}")
            return False

    def search_similar_recipes(self, query: str, top_k: int = 10) -> List[Dict[str, Any]]:
        """Enhanced Blob ë°©ì‹ìš© ìœ ì‚¬ ë ˆì‹œí”¼ ê²€ìƒ‰"""
        try:
            # ì¿¼ë¦¬ ì„ë² ë”© (OpenAI text-embedding-3-small)
            query_embedding = self._get_openai_embedding(query)

            # Enhanced Blob ë°©ì‹ ì „ìš© ê²€ìƒ‰ í•¨ìˆ˜ ì‚¬ìš©
            result = self.supabase.rpc('search_enhanced_recipes', {
                'query_embedding': query_embedding,
                'match_count': top_k
            }).execute()

            if result.data:
                return result.data
            else:
                # fallback: ëª¨ë“  ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ í´ë¼ì´ì–¸íŠ¸ì—ì„œ ê³„ì‚°
                return self._fallback_search(query_embedding, top_k)

        except Exception as e:
            print(f"Error in search: {e}")
            # fallback ê²€ìƒ‰
            query_embedding = self._get_openai_embedding(query)
            return self._fallback_search(query_embedding, top_k)

    def _fallback_search(self, query_embedding: List[float], top_k: int) -> List[Dict[str, Any]]:
        """ë°±ì—… ê²€ìƒ‰ ë°©ë²• - ëª¨ë“  ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ í´ë¼ì´ì–¸íŠ¸ì—ì„œ ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            import numpy as np
            result = self.supabase.table(self.table_name).select('*').execute()

            results = []
            query_embedding = np.array(query_embedding, dtype=np.float32)
            
            for row in result.data:
                embedding_data = row.get('embedding')
                if not embedding_data:
                    continue
                
                # embeddingì´ ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±
                if isinstance(embedding_data, str):
                    try:
                        embedding_data = json.loads(embedding_data)
                    except:
                        continue
                
                stored_embedding = np.array(embedding_data, dtype=np.float32)
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                norm_query = np.linalg.norm(query_embedding)
                norm_stored = np.linalg.norm(stored_embedding)
                
                if norm_query == 0 or norm_stored == 0:
                    similarity = 0.0
                else:
                    similarity = np.dot(query_embedding, stored_embedding) / (norm_query * norm_stored)

                results.append({
                    'recipe_id': row['recipe_id'],
                    'title': row['title'],
                    'enhanced_blob': row.get('enhanced_blob', ''),
                    'metadata': row.get('metadata', {}),
                    'similarity': float(similarity)
                })

            # ìœ ì‚¬ë„ ê¸°ì¤€ ì •ë ¬ í›„ top_k ë°˜í™˜
            results.sort(key=lambda x: x['similarity'], reverse=True)
            return results[:top_k]

        except Exception as e:
            print(f"Error in fallback search: {e}")
            return []

    def load_recipes_from_supabase(self, source_table: str = "recipes_keto_raw", limit: int = 100):
        """Supabaseì˜ ê¸°ì¡´ ë ˆì‹œí”¼ í…Œì´ë¸”ì—ì„œ ë°ì´í„° ë¡œë“œ"""
        try:
            result = self.supabase.table(source_table).select('*').limit(limit).execute()

            processed_count = 0
            for recipe in result.data:
                # Enhanced Blob ì²˜ë¦¬ ë° ì €ì¥
                if self.save_recipe_embedding(recipe):
                    processed_count += 1

                if processed_count % 10 == 0:
                    print(f"Processed {processed_count} recipes...")

            print(f"Total processed: {processed_count} recipes")

        except Exception as e:
            print(f"Error loading recipes from Supabase: {e}")

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    approach = EnhancedBlobApproachSupabase()
    print("Enhanced Blob Approach ì´ˆê¸°í™” ì™„ë£Œ")
    
    # ìƒ˜í”Œ ë ˆì‹œí”¼ë¡œ í…ŒìŠ¤íŠ¸
    sample_recipe = {
        'source_recipe_id': 'test_001',
        'title': 'í‚¤í† ì œë‹‰] ê³ ì†Œí•œë§› ê°€ë“ ì•„ëª¬ë“œ ë¨¸í•€ - No ì„¤íƒ•, No ì½”ì½”ì•„, No ë°€ê°€ë£¨',
        'summary': 'ì•„ëª¬ë“œ ê°€ë£¨ë¡œ ë§Œë“  ê³ ì†Œí•œ ë¨¸í•€',
        'tags': ['í‚¤í† ', 'ë‹¤ì´ì–´íŠ¸', 'ì €íƒ„ìˆ˜'],
        'ingredients': ['ì•„ëª¬ë“œ ê°€ë£¨', 'ê³„ë€', 'ìŠ¤í…Œë¹„ì•„']
    }
    
    # ì €ì¥ í…ŒìŠ¤íŠ¸
    if approach.save_recipe_embedding(sample_recipe):
        print("âœ… ìƒ˜í”Œ ë ˆì‹œí”¼ ì €ì¥ ì„±ê³µ")
        
        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        results = approach.search_similar_recipes("ì•„ëª¬ë“œ ë¨¸í•€", 3)
        print(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
        for i, result in enumerate(results, 1):
            print(f"  {i}. {result['title'][:50]}... ({result['similarity']*100:.1f}%)")
    else:
        print("âŒ ìƒ˜í”Œ ë ˆì‹œí”¼ ì €ì¥ ì‹¤íŒ¨")

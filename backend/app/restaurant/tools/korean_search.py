"""
í•œê¸€ ìµœì í™” ê²€ìƒ‰ ë„êµ¬
PostgreSQL Full-Text Search + pg_trgm + ë²¡í„° ê²€ìƒ‰ í†µí•©
"""

import re
import openai
import asyncio
from typing import List, Dict, Any, Optional
from app.core.database import supabase
from app.core.config import settings

class KoreanSearchTool:
    """í•œê¸€ ìµœì í™” ê²€ìƒ‰ ë„êµ¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.supabase = supabase
        self.openai_client = openai.OpenAI(api_key=settings.openai_api_key)
    
    async def _create_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        try:
            response = self.openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
            return []
    
    def _extract_korean_keywords(self, query: str) -> List[str]:
        """í•œê¸€ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì •ê·œí™”"""
        # í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ì¶”ì¶œ
        keywords = re.findall(r'[ê°€-í£a-zA-Z0-9]+', query)
        
        # 2ê¸€ì ì´ìƒë§Œ í•„í„°ë§
        keywords = [kw for kw in keywords if len(kw) >= 2]
        
        # í•œê¸€ í‚¤ì›Œë“œ ì •ê·œí™” (ì¡°ì‚¬ ì œê±° ë“±)
        normalized_keywords = []
        for keyword in keywords:
            # í•œê¸€ì¸ ê²½ìš° ì¡°ì‚¬ ì œê±°
            if re.match(r'[ê°€-í£]+', keyword):
                # ê°„ë‹¨í•œ ì¡°ì‚¬ ì œê±° (ë” ì •êµí•œ í˜•íƒœì†Œ ë¶„ì„ í•„ìš”ì‹œ KoNLPy ì‚¬ìš©)
                normalized = re.sub(r'(ì„|ë¥¼|ì´|ê°€|ì€|ëŠ”|ì—|ì—ì„œ|ë¡œ|ìœ¼ë¡œ|ì™€|ê³¼|ì˜|ë„|ë§Œ|ê¹Œì§€|ë¶€í„°|ë¶€í„°|í•œí…Œ|ì—ê²Œ)$', '', keyword)
                if len(normalized) >= 2:
                    normalized_keywords.append(normalized)
            else:
                normalized_keywords.append(keyword)
        
        return normalized_keywords
    
    def _generate_query_variants(self, query: str) -> List[str]:
        """ì‚¬ìš©ì ê²€ìƒ‰ì–´ë¥¼ ë‹¤ì–‘í•œ í˜•íƒœë¡œ ì •ê·œí™”í•´ ë³€í˜• ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±.
        - ë¶ˆìš©ì–´ ì œê±°: ë ˆì‹œí”¼/ë§Œë“œëŠ”ë²•/ë§Œë“œëŠ” ë²•/ìš”ë¦¬ ë“±
        - ê³µë°± ì œê±°/í† í° ë¶„ë¦¬/OR í† í°
        """
        q = (query or '').strip()
        if not q:
            return []

        stopwords = ['ë ˆì‹œí”¼', 'ë§Œë“œëŠ”ë²•', 'ë§Œë“œëŠ” ë²•', 'ìš”ë¦¬', 'ë°©ë²•']
        base = q
        for sw in stopwords:
            base = base.replace(sw, '').strip()

        # í† í°í™”(ê³µë°± ê¸°ì¤€)
        tokens = [t for t in base.split() if t]

        variants = []
        variants.append(q)            # ì›ë¬¸
        if base and base != q:
            variants.append(base)     # ë¶ˆìš©ì–´ ì œê±°
        if tokens:
            joined = ' '.join(tokens)
            if joined not in variants:
                variants.append(joined)
            nospace = ''.join(tokens)
            if nospace and nospace not in variants:
                variants.append(nospace)
            # OR í† í°(ë‹¹ê·¼|ë¼í˜|ê¹€ë°¥)
            if len(tokens) > 1:
                or_tokens = '|'.join(tokens)
                variants.append(or_tokens)

        # ì¤‘ë³µ ì œê±° ìœ ì§€ ìˆœì„œ
        seen = set()
        uniq = []
        for v in variants:
            if v and v not in seen:
                uniq.append(v)
                seen.add(v)
        return uniq[:5]

    async def _exact_ilike_search(self, query: str, k: int) -> List[Dict]:
        """ì •í™• ë§¤ì¹­ì— ê°€ê¹Œìš´ ILIKE ê¸°ë°˜ ê²€ìƒ‰(RPC ì‚¬ìš©).
        ë³€í˜• ì¿¼ë¦¬(ë¶ˆìš©ì–´ ì œê±°/ê³µë°± ì œê±°/OR í† í°)ë¥¼ ìˆœì°¨ ì‹œë„í•˜ì—¬
        ìµœì´ˆë¡œ ê²°ê³¼ê°€ ë‚˜ì˜¤ë©´ ê·¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•œë‹¤.
        """
        try:
            if isinstance(self.supabase, type(None)) or hasattr(self.supabase, '__class__') and 'DummySupabase' in str(self.supabase.__class__):
                return []

            for vq in self._generate_query_variants(query):
                try:
                    res = self.supabase.rpc('ilike_search', {'query_text': vq, 'match_count': k}).execute()
                    rows = res.data or []
                    if rows:
                        formatted = []
                        for row in rows:
                            formatted.append({
                                'id': str(row.get('id', '')),
                                'title': row.get('title', 'ì œëª© ì—†ìŒ'),
                                'content': row.get('content', ''),
                                'search_score': row.get('search_score', 1.0),
                                'search_type': 'ilike_exact',
                                'metadata': {kk: vv for kk, vv in row.items() if kk not in ['id','title','content','search_score']}
                            })
                        return formatted
                except Exception as e:
                    print(f"ILIKE ì •í™• ë§¤ì¹­ RPC ì˜¤ë¥˜({vq}): {e}")
                    continue
            return []
        except Exception as e:
            print(f"ILIKE ì •í™• ë§¤ì¹­ ì˜¤ë¥˜: {e}")
            return []
    async def _groonga_search(self, query: str, k: int) -> List[Dict]:
        """PGroonga ê²€ìƒ‰ (ì œëª©/ë³¸ë¬¸ ìš°ì„  ì •í™• ë§¤ì¹­)"""
        try:
            if isinstance(self.supabase, type(None)) or hasattr(self.supabase, '__class__') and 'DummySupabase' in str(self.supabase.__class__):
                return []
            results = self.supabase.rpc('groonga_search', {
                'query_text': query,
                'match_count': k
            }).execute()

            formatted_results = []
            for result in results.data or []:
                formatted_results.append({
                    'id': str(result.get('id', '')),
                    'title': result.get('title', 'ì œëª© ì—†ìŒ'),
                    'content': result.get('content', ''),
                    'search_score': result.get('search_score', 1.0),
                    'search_type': 'pgroonga',
                    'metadata': {k: v for k, v in result.items() if k not in ['id', 'title', 'content', 'search_score']}
                })

            return formatted_results
        except Exception as e:
            print(f"PGroonga ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    async def _full_text_search(self, query: str, k: int) -> List[Dict]:
        """PostgreSQL Full-Text Search (í•œê¸€ ìµœì í™”)"""
        try:
            if isinstance(self.supabase, type(None)) or hasattr(self.supabase, '__class__') and 'DummySupabase' in str(self.supabase.__class__):
                return []
            
            # Full-Text Search ì‹¤í–‰ (RPC í•¨ìˆ˜ ì‚¬ìš©)
            results = self.supabase.rpc('fts_search', {
                'query_text': query,
                'match_count': k
            }).execute()
            
            formatted_results = []
            for result in results.data or []:
                formatted_results.append({
                    'id': str(result.get('id', '')),
                    'title': result.get('title', 'ì œëª© ì—†ìŒ'),
                    'content': result.get('content', ''),
                    'search_score': result.get('search_score', result.get('fts_score', 0.0)),
                    'search_type': 'fts',
                    'metadata': {k: v for k, v in result.items() if k not in ['id', 'title', 'content', 'fts_score']}
                })
            
            return formatted_results
            
        except Exception as e:
            print(f"Full-Text Search ì˜¤ë¥˜: {e}")
            return []
    
    async def _trigram_similarity_search(self, query: str, k: int) -> List[Dict]:
        """Trigram ìœ ì‚¬ë„ ê²€ìƒ‰ (í•œê¸€ ìœ ì‚¬ë„)"""
        try:
            if isinstance(self.supabase, type(None)) or hasattr(self.supabase, '__class__') and 'DummySupabase' in str(self.supabase.__class__):
                return []
            
            # Trigram ìœ ì‚¬ë„ ê²€ìƒ‰ (RPC í•¨ìˆ˜ ì‚¬ìš©)
            results = self.supabase.rpc('trgm_search', {
                'query_text': query,
                'match_count': k
            }).execute()
            
            formatted_results = []
            for result in results.data or []:
                formatted_results.append({
                    'id': str(result.get('id', '')),
                    'title': result.get('title', 'ì œëª© ì—†ìŒ'),
                    'content': result.get('content', ''),
                    'search_score': result.get('search_score', result.get('similarity_score', 0.0)),
                    'search_type': 'trigram',
                    'metadata': {k: v for k, v in result.items() if k not in ['id', 'title', 'content', 'similarity_score']}
                })
            
            return formatted_results
            
        except Exception as e:
            print(f"Trigram ìœ ì‚¬ë„ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    async def _vector_search(self, query: str, query_embedding: List[float], k: int) -> List[Dict]:
        """ë²¡í„° ê²€ìƒ‰ (ê¸°ì¡´)"""
        try:
            if isinstance(self.supabase, type(None)) or hasattr(self.supabase, '__class__') and 'DummySupabase' in str(self.supabase.__class__):
                return []
            
            # ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰ (RPC í•¨ìˆ˜ ì‚¬ìš©)
            results = self.supabase.rpc('vector_search', {
                'q_embedding': query_embedding,
                'k': k
            }).execute()
            
            formatted_results = []
            for result in results.data or []:
                formatted_results.append({
                    'id': str(result.get('id', '')),
                    'title': result.get('title', 'ì œëª© ì—†ìŒ'),
                    'content': result.get('content', ''),
                    'search_score': result.get('search_score', result.get('similarity_score', 0.0)),
                    'search_type': 'vector',
                    'metadata': {k: v for k, v in result.items() if k not in ['id', 'title', 'content', 'similarity_score']}
                })
            
            return formatted_results
            
        except Exception as e:
            print(f"ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    async def _fallback_ilike_search(self, query: str, k: int) -> List[Dict]:
        """í´ë°± ILIKE ê²€ìƒ‰ (ê¸°ì¡´)"""
        try:
            if isinstance(self.supabase, type(None)) or hasattr(self.supabase, '__class__') and 'DummySupabase' in str(self.supabase.__class__):
                return []
            
            keywords = self._extract_korean_keywords(query)
            if not keywords:
                return []
            
            all_results = []
            
            for keyword in keywords[:3]:  # ìƒìœ„ 3ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
                try:
                    # ì œëª©ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
                    title_results = self.supabase.table('recipes_keto_enhanced').select('*').ilike('title', f'%{keyword}%').limit(k).execute()
                    
                    # blob(ë‚´ìš©)ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
                    content_results = self.supabase.table('recipes_keto_enhanced').select('*').ilike('blob', f'%{keyword}%').limit(k).execute()
                    
                    all_results.extend(title_results.data or [])
                    all_results.extend(content_results.data or [])
                    
                except Exception as e:
                    print(f"í‚¤ì›Œë“œ ê²€ìƒ‰ ì˜¤ë¥˜ for '{keyword}': {e}")
                    continue
            
            # ì¤‘ë³µ ì œê±°
            seen_ids = set()
            unique_results = []
            for result in all_results:
                result_id = result.get('id')
                if result_id and result_id not in seen_ids:
                    seen_ids.add(result_id)
                    unique_results.append(result)
            
            # ê²°ê³¼ í¬ë§·íŒ…
            formatted_results = []
            for result in unique_results:
                formatted_results.append({
                    'id': str(result.get('id', '')),
                    'title': result.get('title', 'ì œëª© ì—†ìŒ'),
                    'content': result.get('content', ''),
                    'search_score': 0.5,  # ILIKE ê²€ìƒ‰ ê¸°ë³¸ ì ìˆ˜
                    'search_type': 'ilike',
                    'metadata': {k: v for k, v in result.items() if k not in ['id', 'title', 'content']}
                })
            
            return formatted_results[:k]
            
        except Exception as e:
            print(f"í´ë°± ILIKE ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    async def korean_hybrid_search(self, query: str, k: int = 5) -> List[Dict]:
        """í•œê¸€ ìµœì í™” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ìŠ¤ë§ˆíŠ¸ ê°œì„ )"""
        try:
            print(f"ğŸ” í•œê¸€ ìµœì í™” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œì‘: '{query}'")
            
            all_results = []
            search_strategy = "hybrid"
            search_message = ""
            
            # 0ë‹¨ê³„: ILIKE ê¸°ë°˜ ì •í™• ë§¤ì¹­(ê°€ì¥ ë‹¨ìˆœÂ·ì•ˆì •)
            print("  ğŸ” 0ë‹¨ê³„: ILIKE ì •í™• ë§¤ì¹­ ê²€ìƒ‰...")
            ilike_exact = await self._exact_ilike_search(query, k)
            if ilike_exact:
                print(f"    âœ… ILIKE ì •í™• ë§¤ì¹­ ë°œê²¬: {len(ilike_exact)}ê°œ")
                search_strategy = "exact"
                search_message = "ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤."
                for result in ilike_exact:
                    result['final_score'] = result['search_score'] * 2.2
                all_results.extend(ilike_exact)
            else:
                print("    âš ï¸ ILIKE ì •í™• ë§¤ì¹­ ì—†ìŒ â†’ FTS ë‹¨ê³„ë¡œ")

            # 1ë‹¨ê³„: ì •í™•í•œ ë§¤ì¹­ ì‹œë„ (Full-Text Search ìš°ì„ )
            print("  ğŸ“ 1ë‹¨ê³„: ì •í™•í•œ ë§¤ì¹­ ê²€ìƒ‰...")
            fts_results = await self._full_text_search(query, k)
            if fts_results and any(result['search_score'] > 0.1 for result in fts_results):
                print(f"    âœ… ì •í™•í•œ ë§¤ì¹­ ë°œê²¬: {len(fts_results)}ê°œ")
                search_strategy = "exact"
                search_message = "ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤."
                for result in fts_results:
                    result['final_score'] = result['search_score'] * 2.0  # ì •í™•í•œ ë§¤ì¹­ ê°€ì¤‘ì¹˜ ì¦ê°€
                all_results.extend(fts_results)
            else:
                print("    âš ï¸ ì •í™•í•œ ë§¤ì¹­ ì—†ìŒ, ë¶€ë¶„ ë§¤ì¹­ ì‹œë„...")
                
                # 2ë‹¨ê³„: ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (Trigram + ILIKE)
                print("  ğŸ”¤ 2ë‹¨ê³„: ë¶€ë¶„ ë§¤ì¹­ ê²€ìƒ‰...")
                trigram_results = await self._trigram_similarity_search(query, k)
                ilike_results = await self._fallback_ilike_search(query, k)
                
                if trigram_results or ilike_results:
                    print(f"    âœ… ë¶€ë¶„ ë§¤ì¹­ ë°œê²¬: Trigram {len(trigram_results)}ê°œ, ILIKE {len(ilike_results)}ê°œ")
                    search_strategy = "partial"
                    search_message = "ì •í™•í•œ ê²€ìƒ‰ì–´ê°€ ì—†ì–´ì„œ ê´€ë ¨ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤."
                    
                    # Trigram ê²°ê³¼ ì²˜ë¦¬
                    for result in trigram_results:
                        result['final_score'] = result['search_score'] * 1.5  # ë¶€ë¶„ ë§¤ì¹­ ê°€ì¤‘ì¹˜
                    all_results.extend(trigram_results)
                    
                    # ILIKE ê²°ê³¼ ì²˜ë¦¬
                    for result in ilike_results:
                        result['final_score'] = result['search_score'] * 1.0  # ê¸°ë³¸ ê°€ì¤‘ì¹˜
                    all_results.extend(ilike_results)
                else:
                    print("    âš ï¸ ë¶€ë¶„ ë§¤ì¹­ë„ ì—†ìŒ, í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œë„...")
                    
                    # 3ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ëª¨ë“  ë°©ì‹)
                    print("  ğŸ”„ 3ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰...")
                    search_strategy = "hybrid"
                    search_message = "ì¢…í•© ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤."
                    
                    # ë²¡í„° ê²€ìƒ‰ (ê°€ì¤‘ì¹˜ 40%)
                    print("    ğŸ“Š ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰...")
                    query_embedding = await self._create_embedding(query)
                    if query_embedding:
                        vector_results = await self._vector_search(query, query_embedding, k)
                        for result in vector_results:
                            result['final_score'] = result['search_score'] * 0.4
                        all_results.extend(vector_results)
                    
                    # Full-Text Search (ê°€ì¤‘ì¹˜ 30%)
                    print("    ğŸ“ Full-Text Search ì‹¤í–‰...")
                    fts_results = await self._full_text_search(query, k)
                    for result in fts_results:
                        result['final_score'] = result['search_score'] * 0.3
                    all_results.extend(fts_results)
                    
                    # Trigram ìœ ì‚¬ë„ ê²€ìƒ‰ (ê°€ì¤‘ì¹˜ 20%)
                    print("    ğŸ”¤ Trigram ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤í–‰...")
                    trigram_results = await self._trigram_similarity_search(query, k)
                    for result in trigram_results:
                        result['final_score'] = result['search_score'] * 0.2
                    all_results.extend(trigram_results)
                    
                    # í´ë°± ILIKE ê²€ìƒ‰ (ê°€ì¤‘ì¹˜ 10%)
                    print("    ğŸ” ILIKE í´ë°± ê²€ìƒ‰ ì‹¤í–‰...")
                    ilike_results = await self._fallback_ilike_search(query, k)
                    for result in ilike_results:
                        result['final_score'] = result['search_score'] * 0.1
                    all_results.extend(ilike_results)
            
            # ê²°ê³¼ í†µí•© ë° ì •ë ¬
            if not all_results:
                print("    âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            # ì¤‘ë³µ ì œê±° (ID ê¸°ì¤€)
            seen_ids = set()
            unique_results = []
            for result in all_results:
                result_id = result.get('id')
                if result_id and result_id not in seen_ids:
                    seen_ids.add(result_id)
                    unique_results.append(result)
                elif result_id in seen_ids:
                    # ì¤‘ë³µëœ ê²½ìš° ë” ë†’ì€ ì ìˆ˜ë¡œ ì—…ë°ì´íŠ¸
                    for i, existing in enumerate(unique_results):
                        if existing.get('id') == result_id and result['final_score'] > existing['final_score']:
                            unique_results[i] = result
                            break
            
            # ìµœì¢… ì ìˆ˜ë¡œ ì •ë ¬
            unique_results.sort(key=lambda x: x['final_score'], reverse=True)
            
            # ìƒìœ„ kê°œ ê²°ê³¼ ë°˜í™˜
            final_results = unique_results[:k]
            
            # ê²€ìƒ‰ ì „ëµê³¼ ë©”ì‹œì§€ ì¶”ê°€
            for result in final_results:
                result['search_strategy'] = search_strategy
                result['search_message'] = search_message
            
            print(f"  âœ… ìµœì¢… ê²°ê³¼: {len(final_results)}ê°œ (ì „ëµ: {search_strategy})")
            print(f"  ğŸ’¬ {search_message}")
            
            # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            for i, result in enumerate(final_results[:3], 1):
                print(f"    {i}. {result['title']} (ì ìˆ˜: {result['final_score']:.3f}, íƒ€ì…: {result['search_type']})")
            
            return final_results
            
        except Exception as e:
            print(f"âŒ í•œê¸€ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    async def search(self, query: str, profile: str = "", max_results: int = 5) -> List[Dict]:
        """ê°„ë‹¨í•œ ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤ (í•œê¸€ ìµœì í™” + ìŠ¤ë§ˆíŠ¸ ê°œì„ )"""
        try:
            # í”„ë¡œí•„ì—ì„œ í•„í„° ì¶”ì¶œ
            filters = {}
            if profile:
                if "ì•„ì¹¨" in profile or "morning" in profile.lower():
                    filters['category'] = 'ì•„ì¹¨'
                if "ì‰¬ìš´" in profile or "easy" in profile.lower():
                    filters['difficulty'] = 'ì‰¬ì›€'
            
            # ë©”ì‹œì§€ì—ì„œ ì‹ì‚¬-ì‹œê°„ í‚¤ì›Œë“œ ê°ì§€ â†’ ë³´ì¡° í‚¤ì›Œë“œë¡œ ê°•í™”
            adjusted_query = query
            meal_hint = None
            if any(k in query for k in ["ì•„ì¹¨", "ë¸Œë ‰í¼ìŠ¤íŠ¸", "ì•„ì¹¨ì‹ì‚¬", "morning", "breakfast"]):
                meal_hint = 'ì•„ì¹¨'
                adjusted_query = f"{query} ì˜¤ë¯ˆë › ê³„ë€ ìƒëŸ¬ë“œ ìš”ê±°íŠ¸"
            elif any(k in query for k in ["ì ì‹¬", "ëŸ°ì¹˜", "lunch"]):
                meal_hint = 'ì ì‹¬'
                adjusted_query = f"{query} ìƒëŸ¬ë“œ ìŠ¤í…Œì´í¬ ë³¶ìŒ êµ¬ì´"
            elif any(k in query for k in ["ì €ë…", "ë””ë„ˆ", "dinner"]):
                meal_hint = 'ì €ë…'
                adjusted_query = f"{query} ìŠ¤í…Œì´í¬ êµ¬ì´ ì°œ ë³¶ìŒ"

            # ìŠ¤ë§ˆíŠ¸ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰(ê°•í™” ì¿¼ë¦¬ ìš°ì„ )
            results = await self.korean_hybrid_search(adjusted_query, max_results)
            if not results and adjusted_query != query:
                results = await self.korean_hybrid_search(query, max_results)
            
            # ê²°ê³¼ í¬ë§·íŒ… (ê²€ìƒ‰ ì „ëµê³¼ ë©”ì‹œì§€ í¬í•¨)
            formatted_results = []
            search_message = ""
            search_strategy = "unknown"
            
            for result in results:
                # ì²« ë²ˆì§¸ ê²°ê³¼ì—ì„œ ê²€ìƒ‰ ì „ëµê³¼ ë©”ì‹œì§€ ì¶”ì¶œ
                if not search_message:
                    search_message = result.get('search_message', '')
                    search_strategy = result.get('search_strategy', 'unknown')
                    if meal_hint and not search_message:
                        search_message = f"'{meal_hint}' í‚¤ì›Œë“œë¥¼ ë°˜ì˜í•´ ë ˆì‹œí”¼ë¥¼ ì¶”ì²œí–ˆìŠµë‹ˆë‹¤."
                
                formatted_results.append({
                    'title': result.get('title', 'ì œëª© ì—†ìŒ'),
                    'content': result.get('content', ''),
                    'similarity': result.get('final_score', 0.0),
                    'metadata': result.get('metadata', {}),
                    'search_types': [result.get('search_type', 'hybrid')],
                    'search_strategy': search_strategy
                })
            
            # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ë©”ì‹œì§€ ì¶”ê°€
            if not formatted_results:
                formatted_results.append({
                    'title': 'ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ',
                    'content': 'ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.',
                    'similarity': 0.0,
                    'metadata': {'search_message': 'ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.'},
                    'search_types': ['none'],
                    'search_strategy': 'none'
                })
            
            # ê²€ìƒ‰ ë©”ì‹œì§€ ì¶œë ¥
            if search_message:
                print(f"ğŸ’¬ ì‚¬ìš©ì ì•ˆë‚´: {search_message}")
            
            return formatted_results
            
        except Exception as e:
            print(f"Search error: {e}")
            return [{
                'title': 'ê²€ìƒ‰ ì˜¤ë¥˜',
                'content': f'ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}',
                'similarity': 0.0,
                'metadata': {'error': str(e)},
                'search_types': ['error'],
                'search_strategy': 'error'
            }]

    async def smart_search(self, query: str, k: int = 5) -> Dict[str, Any]:
        """ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ (ì‚¬ìš©ì í”¼ë“œë°± í¬í•¨)"""
        try:
            print(f"ğŸ§  ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ì‹œì‘: '{query}'")
            
            # 1ë‹¨ê³„: ì •í™•í•œ ë§¤ì¹­ ì‹œë„
            print("  ğŸ¯ 1ë‹¨ê³„: ì •í™•í•œ ë§¤ì¹­ ê²€ìƒ‰...")
            fts_results = await self._full_text_search(query, k)
            
            if fts_results and any(result['search_score'] > 0.1 for result in fts_results):
                print(f"    âœ… ì •í™•í•œ ë§¤ì¹­ ë°œê²¬: {len(fts_results)}ê°œ")
                return {
                    'results': fts_results,
                    'search_strategy': 'exact',
                    'message': 'ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.',
                    'total_count': len(fts_results)
                }
            
            # 2ë‹¨ê³„: ë¶€ë¶„ ë§¤ì¹­ ì‹œë„
            print("  ğŸ” 2ë‹¨ê³„: ë¶€ë¶„ ë§¤ì¹­ ê²€ìƒ‰...")
            trigram_results = await self._trigram_similarity_search(query, k)
            ilike_results = await self._fallback_ilike_search(query, k)
            
            if trigram_results or ilike_results:
                print(f"    âœ… ë¶€ë¶„ ë§¤ì¹­ ë°œê²¬: Trigram {len(trigram_results)}ê°œ, ILIKE {len(ilike_results)}ê°œ")
                
                # ê²°ê³¼ í†µí•©
                all_partial_results = []
                all_partial_results.extend(trigram_results)
                all_partial_results.extend(ilike_results)
                
                # ì¤‘ë³µ ì œê±°
                seen_ids = set()
                unique_results = []
                for result in all_partial_results:
                    result_id = result.get('id')
                    if result_id and result_id not in seen_ids:
                        seen_ids.add(result_id)
                        unique_results.append(result)
                
                return {
                    'results': unique_results[:k],
                    'search_strategy': 'partial',
                    'message': 'ì •í™•í•œ ê²€ìƒ‰ì–´ê°€ ì—†ì–´ì„œ ê´€ë ¨ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤.',
                    'total_count': len(unique_results)
                }
            
            # 3ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
            print("  ğŸ”„ 3ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰...")
            hybrid_results = await self.korean_hybrid_search(query, k)
            
            if hybrid_results:
                return {
                    'results': hybrid_results,
                    'search_strategy': 'hybrid',
                    'message': 'ì¢…í•© ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.',
                    'total_count': len(hybrid_results)
                }
            
            # 4ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ
            print("    âŒ ëª¨ë“  ê²€ìƒ‰ ë°©ì‹ì—ì„œ ê²°ê³¼ ì—†ìŒ")
            return {
                'results': [],
                'search_strategy': 'none',
                'message': 'ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.',
                'total_count': 0
            }
            
        except Exception as e:
            print(f"âŒ ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return {
                'results': [],
                'search_strategy': 'error',
                'message': f'ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}',
                'total_count': 0
            }

# ì „ì—­ í•œê¸€ ê²€ìƒ‰ ë„êµ¬ ì¸ìŠ¤í„´ìŠ¤
korean_search_tool = KoreanSearchTool()

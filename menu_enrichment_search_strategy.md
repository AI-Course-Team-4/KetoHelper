# ë©”ë‰´ ì •ë³´ ì¸í„°ë„· ê²€ìƒ‰ ì¦ê°• ì „ëµ

## ğŸ¯ ê°œìš”
ë©”ë‰´ëª…ë§Œìœ¼ë¡œëŠ” íŒë‹¨í•˜ê¸° ì–´ë ¤ìš´ ê²½ìš° ì¸í„°ë„· ê²€ìƒ‰ì„ í†µí•´ ë©”ë‰´ ì •ë³´ë¥¼ ë³´ì™„í•˜ëŠ” ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ“‹ êµ¬í˜„ ë‹¨ê³„

### **Phase 1: ê°„ë‹¨í•œ í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ (ì¶”ì²œ ì‹œì‘ì )**

#### **1.1 ê¸°ë³¸ êµ¬ì¡°**
```python
def enrich_menu_with_fallback(menu_name, restaurant_context=None):
    # 1ë‹¨ê³„: ê¸°ë³¸ ê·œì¹™ìœ¼ë¡œ ì‹œë„
    basic_info = apply_simple_rules(menu_name)
    
    # 2ë‹¨ê³„: ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ ê²€ìƒ‰ìœ¼ë¡œ ë³´ì™„
    if basic_info.confidence < 0.6 or len(basic_info.get("main_ingredients", [])) < 3:
        search_info = await search_menu_simple(menu_name, restaurant_context)
        basic_info = merge_enrichment_data(basic_info, search_info)
    
    return basic_info
```

#### **1.2 ê°„ë‹¨í•œ ì›¹ ê²€ìƒ‰ (playwright-fetch)**
```python
async def search_menu_simple(menu_name, restaurant_name=None):
    """ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ìœ¼ë¡œ ë©”ë‰´ ì •ë³´ ë³´ì™„"""
    
    # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    queries = [
        f"{menu_name} ë ˆì‹œí”¼",
        f"{menu_name} ì¬ë£Œ",
        f"{restaurant_name} {menu_name}" if restaurant_name else menu_name
    ]
    
    search_results = []
    
    for query in queries:
        try:
            search_url = f"https://search.naver.com/search.naver?query={query}"
            content = await playwright_fetch(search_url)
            
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
            ingredients = extract_ingredients_from_text(content)
            if ingredients:
                search_results.extend(ingredients)
                
        except Exception as e:
            logger.warning(f"ê²€ìƒ‰ ì‹¤íŒ¨: {query} - {e}")
            continue
    
    return {
        "main_ingredients": list(set(search_results))[:5],  # ì¤‘ë³µ ì œê±°, ìµœëŒ€ 5ê°œ
        "source": "search",
        "confidence": min(len(search_results) / 5, 1.0)  # ì¬ë£Œ ê°œìˆ˜ ê¸°ë°˜ ì‹ ë¢°ë„
    }
```

#### **1.3 ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­**
```python
def extract_ingredients_from_text(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì¬ë£Œ ì •ë³´ ì¶”ì¶œ"""
    
    # ì¬ë£Œ ê´€ë ¨ íŒ¨í„´
    patterns = [
        r"ì£¼ì¬ë£Œ[:\s]*([^,\.]+)",
        r"ì¬ë£Œ[:\s]*([^,\.]+)",
        r"í•„ìš”ì¬ë£Œ[:\s]*([^,\.]+)",
        r"ì¤€ë¹„ë¬¼[:\s]*([^,\.]+)"
    ]
    
    # ì¼ë°˜ì ì¸ ì¬ë£Œ í‚¤ì›Œë“œ
    common_ingredients = [
        "ë¼ì§€ê³ ê¸°", "ì†Œê³ ê¸°", "ë‹­ê³ ê¸°", "ìƒì„ ", "ìƒˆìš°", "ì˜¤ì§•ì–´", "ë¬¸ì–´",
        "ê¹€ì¹˜", "ë‘ë¶€", "ì½©ë‚˜ë¬¼", "ì‹œê¸ˆì¹˜", "ë‹¹ê·¼", "ì–‘íŒŒ", "ë§ˆëŠ˜",
        "ê³ ì¶”ì¥", "ëœì¥", "ê°„ì¥", "ì°¸ê¸°ë¦„", "ë“¤ê¸°ë¦„", "ì‹ìš©ìœ ",
        "ë°¥", "êµ­ìˆ˜", "ë©´", "ë–¡", "ë§Œë‘", "ê¹€", "ê³„ë€"
    ]
    
    ingredients = []
    
    # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì¶”ì¶œ
    for pattern in patterns:
        matches = re.findall(pattern, text)
        for match in matches:
            # ì‰¼í‘œë‚˜ ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬
            items = re.split(r'[,ï¼Œ\s]+', match.strip())
            ingredients.extend([item.strip() for item in items if item.strip()])
    
    # ì¼ë°˜ ì¬ë£Œ í‚¤ì›Œë“œ ê²€ìƒ‰
    for ingredient in common_ingredients:
        if ingredient in text:
            ingredients.append(ingredient)
    
    return list(set(ingredients))  # ì¤‘ë³µ ì œê±°
```

#### **1.4 ë°ì´í„° ë³‘í•© ë¡œì§**
```python
def merge_enrichment_data(basic_info, search_info):
    """ê¸°ë³¸ ì •ë³´ì™€ ê²€ìƒ‰ ì •ë³´ ë³‘í•©"""
    
    merged = basic_info.copy()
    
    # ì¬ë£Œ ì •ë³´ ë³‘í•© (ì¤‘ë³µ ì œê±°)
    basic_ingredients = set(basic_info.get("main_ingredients", []))
    search_ingredients = set(search_info.get("main_ingredients", []))
    merged["main_ingredients"] = list(basic_ingredients.union(search_ingredients))[:5]
    
    # ì‹ ë¢°ë„ ì—…ë°ì´íŠ¸
    if search_info.get("confidence", 0) > basic_info.get("confidence", 0):
        merged["confidence"] = search_info["confidence"]
        merged["source"] = "hybrid"  # ê¸°ë³¸ + ê²€ìƒ‰
    
    return merged
```

### **Phase 2: ê³ ë„í™” (í•„ìš”ì‹œ ì—…ê·¸ë ˆì´ë“œ)**

#### **2.1 ë‹¤ì¤‘ ê²€ìƒ‰ ì—”ì§„ í™œìš©**
```python
async def search_menu_advanced(menu_name, restaurant_context=None):
    """ë‹¤ì¤‘ ê²€ìƒ‰ ì—”ì§„ìœ¼ë¡œ ë©”ë‰´ ì •ë³´ ìˆ˜ì§‘"""
    
    search_engines = [
        ("naver", f"https://search.naver.com/search.naver?query={menu_name}+ë ˆì‹œí”¼"),
        ("google", f"https://www.google.com/search?q={menu_name}+ì¬ë£Œ"),
        ("youtube", f"https://www.youtube.com/results?search_query={menu_name}+ìš”ë¦¬")
    ]
    
    all_results = []
    
    for engine, url in search_engines:
        try:
            content = await playwright_fetch(url)
            results = extract_ingredients_from_text(content)
            all_results.extend(results)
            
            # Rate limiting
            await asyncio.sleep(1)
            
        except Exception as e:
            logger.warning(f"{engine} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
    
    return {
        "main_ingredients": list(set(all_results))[:5],
        "source": "multi_search",
        "confidence": min(len(all_results) / 10, 1.0)
    }
```

#### **2.2 ê²€ìƒ‰ API í™œìš© (Google Custom Search)**
```python
import requests

async def search_with_google_api(menu_name, api_key, search_engine_id):
    """Google Custom Search API í™œìš©"""
    
    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        "key": api_key,
        "cx": search_engine_id,
        "q": f"{menu_name} ë ˆì‹œí”¼ ì¬ë£Œ",
        "num": 5
    }
    
    try:
        response = requests.get(url, params=params)
        data = response.json()
        
        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        search_text = ""
        for item in data.get("items", []):
            search_text += item.get("snippet", "") + " "
        
        ingredients = extract_ingredients_from_text(search_text)
        
        return {
            "main_ingredients": ingredients,
            "source": "google_api",
            "confidence": 0.8  # API ê²°ê³¼ëŠ” ë†’ì€ ì‹ ë¢°ë„
        }
        
    except Exception as e:
        logger.error(f"Google API ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return {"main_ingredients": [], "source": "api_failed", "confidence": 0.0}
```

#### **2.3 AI ê¸°ë°˜ ì •ë³´ ì¶”ì¶œ**
```python
async def extract_with_llm(menu_name, search_context):
    """LLMì„ í™œìš©í•œ ì •êµí•œ ì •ë³´ ì¶”ì¶œ"""
    
    prompt = f"""
    ë‹¤ìŒ ë©”ë‰´ì— ëŒ€í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
    ë©”ë‰´ëª…: {menu_name}
    ê²€ìƒ‰ ê²°ê³¼: {search_context}
    
    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
    - ì£¼ì¬ë£Œ: (ìµœëŒ€ 5ê°œ)
    - ì¡°ë¦¬ë²•: (grill, stew, stir-fry ë“±)
    - ë§¤ìš´ ì •ë„: (0-3)
    - ì˜¨ë„: (hot, cold, room)
    - ì•Œë ˆë¥´ê¸°: (ê³„ë€, ìš°ìœ , ëŒ€ë‘, ê°‘ê°ë¥˜ ë“±)
    """
    
    # OpenAI API ë˜ëŠ” ë¡œì»¬ LLM í˜¸ì¶œ
    response = await call_llm_api(prompt)
    
    return parse_llm_response(response)
```

### **Phase 3: ìµœì í™” ë° ëª¨ë‹ˆí„°ë§**

#### **3.1 ìºì‹± ì‹œìŠ¤í…œ**
```python
class MenuSearchCache:
    def __init__(self, db_connection):
        self.db = db_connection
    
    async def get_cached_result(self, menu_name):
        """ìºì‹œëœ ê²€ìƒ‰ ê²°ê³¼ ì¡°íšŒ"""
        query = """
        SELECT search_result, created_at 
        FROM menu_search_cache 
        WHERE menu_name = %s AND created_at > NOW() - INTERVAL '7 days'
        """
        result = await self.db.fetch_one(query, (menu_name,))
        return result
    
    async def cache_result(self, menu_name, search_result):
        """ê²€ìƒ‰ ê²°ê³¼ ìºì‹œ ì €ì¥"""
        query = """
        INSERT INTO menu_search_cache (menu_name, search_result, created_at)
        VALUES (%s, %s, NOW())
        ON CONFLICT (menu_name) DO UPDATE SET
        search_result = EXCLUDED.search_result,
        created_at = EXCLUDED.created_at
        """
        await self.db.execute(query, (menu_name, json.dumps(search_result)))
```

#### **3.2 í’ˆì§ˆ ëª¨ë‹ˆí„°ë§**
```python
def monitor_search_quality():
    """ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§"""
    
    metrics = {
        "search_success_rate": 0,
        "avg_ingredients_found": 0,
        "confidence_distribution": {},
        "source_effectiveness": {}
    }
    
    # ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„±
    generate_daily_report(metrics)
    
    # í’ˆì§ˆì´ ë‚®ì€ ë©”ë‰´ ì‹ë³„
    low_quality_menus = identify_low_quality_menus()
    
    return metrics, low_quality_menus
```

## ğŸš€ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### **1ë‹¨ê³„ (ì¦‰ì‹œ êµ¬í˜„)**
- âœ… ê°„ë‹¨í•œ ë„¤ì´ë²„ ê²€ìƒ‰ (playwright-fetch)
- âœ… ê¸°ë³¸ íŒ¨í„´ ë§¤ì¹­
- âœ… í•˜ì´ë¸Œë¦¬ë“œ í’ë¶€í™” ë¡œì§

### **2ë‹¨ê³„ (1-2ì£¼ í›„)**
- âœ… ë‹¤ì¤‘ ê²€ìƒ‰ ì—”ì§„
- âœ… ìºì‹± ì‹œìŠ¤í…œ
- âœ… í’ˆì§ˆ ëª¨ë‹ˆí„°ë§

### **3ë‹¨ê³„ (í•„ìš”ì‹œ)**
- âœ… Google API ì—°ë™
- âœ… LLM ê¸°ë°˜ ì¶”ì¶œ
- âœ… ê³ ê¸‰ í’ˆì§ˆ ê²€ì¦

## ğŸ“Š ì„±ëŠ¥ ì§€í‘œ

### **ëª©í‘œ ì§€í‘œ**
- **ê²€ìƒ‰ ì„±ê³µë¥ **: â‰¥ 80%
- **í‰ê·  ì¬ë£Œ ì¶”ì¶œ**: â‰¥ 3ê°œ
- **ì‘ë‹µ ì‹œê°„**: â‰¤ 5ì´ˆ
- **ìºì‹œ íˆíŠ¸ìœ¨**: â‰¥ 60%

### **ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ**
- ê²€ìƒ‰ ì„±ê³µ/ì‹¤íŒ¨ìœ¨
- ì¬ë£Œ ì¶”ì¶œ ê°œìˆ˜ ë¶„í¬
- ì†ŒìŠ¤ë³„ íš¨ê³¼ì„±
- ì‘ë‹µ ì‹œê°„ íŠ¸ë Œë“œ

## ğŸ”§ ì„¤ì • íŒŒì¼ ì˜ˆì‹œ

### **search_config.yaml**
```yaml
search_engines:
  naver:
    enabled: true
    rate_limit: 1.0  # requests per second
    timeout: 10
  google:
    enabled: false
    api_key: ""
    search_engine_id: ""
    rate_limit: 0.5

extraction:
  max_ingredients: 5
  confidence_threshold: 0.6
  cache_ttl_days: 7

patterns:
  ingredient_patterns:
    - "ì£¼ì¬ë£Œ[:\s]*([^,\.]+)"
    - "ì¬ë£Œ[:\s]*([^,\.]+)"
  common_ingredients:
    - "ë¼ì§€ê³ ê¸°"
    - "ì†Œê³ ê¸°"
    - "ê¹€ì¹˜"
    # ... ë” ë§ì€ ì¬ë£Œ
```

---
**ì‘ì„±ì¼**: 2025-01-27  
**ë²„ì „**: v1.0  
**ìƒíƒœ**: êµ¬í˜„ ì¤€ë¹„ ì™„ë£Œ
